{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet5 与 AlexNet\n",
    "\n",
    "### LeNet5 现代CNN的奠基者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入-> (卷积+池化)-> (卷积+池化)-> (线性*2)-> 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(size=(10,1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.pool2 = nn.AvgPool2d(2)\n",
    "        self.fc1 = nn.Linear(5*5*16,120) # weight(120,400)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # 线性前，数据拉平\n",
    "        x = x.view(-1,5*5*16) # -1:占位符，自动计算\n",
    "        x = F.tanh(self.fc1(x)) \n",
    "        output = F.softmax(self.fc2(x),dim=1) # (samples,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model() # 实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feishuoren/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchinfo\n",
    "# $ pip install torchinfo\n",
    "# jupyter !pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    --                        --\n",
       "├─Conv2d: 1-1                            [10, 6, 28, 28]           156\n",
       "├─AvgPool2d: 1-2                         [10, 6, 14, 14]           --\n",
       "├─Conv2d: 1-3                            [10, 16, 10, 10]          2,416\n",
       "├─AvgPool2d: 1-4                         [10, 16, 5, 5]            --\n",
       "├─Linear: 1-5                            [10, 120]                 48,120\n",
       "├─Linear: 1-6                            [10, 84]                  10,164\n",
       "==========================================================================================\n",
       "Total params: 60,856\n",
       "Trainable params: 60,856\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.22\n",
       "==========================================================================================\n",
       "Input size (MB): 0.04\n",
       "Forward/backward pass size (MB): 0.52\n",
       "Params size (MB): 0.24\n",
       "Estimated Total Size (MB): 0.81\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net, input_size=(10,1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单一的LeNet5在Fashion-MNIST数据集准确率超过91%，效果比只有线性层提升了5%\n",
    "# 不能适用于大的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet 从浅层到深度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “视觉界奥林匹克” 大规模视觉识别挑战比赛ILSVRC，AlexNet出现后停赛\n",
    "# ILSVRC 使用 ImageNet数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet\n",
    "# 输入-> (卷积+池化)-> (卷积+池化)-> (卷积*3+池化)-> (线性*3)-> 输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比较LeNet5的优化：\n",
    "- 使用更深的网络\n",
    "- 卷积核要小\n",
    "- 增加通道数（特征图数）\n",
    "\n",
    "使用了relu激活函数\n",
    "\n",
    "防止过拟合\n",
    "- FC前有 Dropout层\n",
    "- 使用图像增强技术，扩充数据集\n",
    "\n",
    "提出使用GPU训练神经网络、重叠池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(size=(10,3,227,227)) # 原论文224*224（表示图像的大小）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        # 为了处理尺寸较大的原始图片，先使用11*11的卷积核和较大的步长快速降低特征图的尺寸\n",
    "        # 同时，使用比较多的通道数，来弥补降低尺寸造成的数据损失\n",
    "        self.conv1 = nn.Conv2d(3,96,kernel_size=11,stride=4)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3,stride=2) # 池化感受野重叠\n",
    "        \n",
    "        # 卷积核、步长恢复到业界常用的大小，进一步扩大通道来提取数据\n",
    "        # 通过padding让特征图尺寸不要缩小，为后续网络提供更多可能性\n",
    "        # 已经将特征图尺寸缩小到27*27，计算量可控，可以开始进行特征提取了\n",
    "        self.conv2 = nn.Conv2d(96,256,kernel_size=5,padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        # 疯狂提取特征，连续用多个卷积层\n",
    "        # stride=1时，kernel_size=5,padding=2 或 kernel_size=3,padding=1 的搭配可以维持特征图大小不变\n",
    "        self.conv3 = nn.Conv2d(256,384,kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(384,384,kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(384,256,kernel_size=3,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        # 特征图尺寸到了6*6（一般经典卷积神经网络特征图尺寸控制到5-7之间，再传入全连接网络）\n",
    "        # 线性层降低数据维度后，对信息有汇总作用\n",
    "        self.fc1 = nn.Linear(6*6*256,4096) # 上层所有特征图的所有像素\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "        self.fc3 = nn.Linear(4096,1000) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(-1,6*6*256)\n",
    "        x = F.relu(F.dropout(self.fc1(x),p=0.5))\n",
    "        x = F.relu(F.dropout(self.fc2(x),p=0.5))\n",
    "        output = F.softmax(self.fc3(x),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    --                        --\n",
       "├─Conv2d: 1-1                            [10, 96, 55, 55]          34,944\n",
       "├─MaxPool2d: 1-2                         [10, 96, 27, 27]          --\n",
       "├─Conv2d: 1-3                            [10, 256, 27, 27]         614,656\n",
       "├─MaxPool2d: 1-4                         [10, 256, 13, 13]         --\n",
       "├─Conv2d: 1-5                            [10, 384, 13, 13]         885,120\n",
       "├─Conv2d: 1-6                            [10, 384, 13, 13]         1,327,488\n",
       "├─Conv2d: 1-7                            [10, 256, 13, 13]         884,992\n",
       "├─MaxPool2d: 1-8                         [10, 256, 6, 6]           --\n",
       "├─Linear: 1-9                            [10, 4096]                37,752,832\n",
       "├─Linear: 1-10                           [10, 4096]                16,781,312\n",
       "├─Linear: 1-11                           [10, 1000]                4,097,000\n",
       "==========================================================================================\n",
       "Total params: 62,378,344\n",
       "Trainable params: 62,378,344\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 11.36\n",
       "==========================================================================================\n",
       "Input size (MB): 6.18\n",
       "Forward/backward pass size (MB): 52.74\n",
       "Params size (MB): 249.51\n",
       "Estimated Total Size (MB): 308.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net,input_size=(10,3,227,227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步长，缩小特征图尺寸\n",
    "# padding 小于 kernel_size的1/2\n",
    "# 卷积核尺寸小\n",
    "# 特征图最后尺寸5*5 7*7 9*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # block1\n",
    "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # block2\n",
    "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128,128,3,padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # block3\n",
    "        self.conv5 = nn.Conv2d(128,256,3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(256,256,3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(256,256,3,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # block4\n",
    "        self.conv8 = nn.Conv2d(256,512,3,padding=1)\n",
    "        self.conv9 = nn.Conv2d(512,512,3,padding=1)\n",
    "        self.conv10 = nn.Conv2d(512,512,3,padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # block5\n",
    "        self.conv11 = nn.Conv2d(512,512,3,padding=1)\n",
    "        self.conv12 = nn.Conv2d(512,512,3,padding=1)\n",
    "        self.conv13 = nn.Conv2d(512,512,3,padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # FC 层\n",
    "        self.fc1 = nn.Linear(512*7*7,4096)\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "        self.fc3 = nn.Linear(4096,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(F.relu(self.conv7(x)))\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.pool4(F.relu(self.conv10(x)))\n",
    "        \n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = self.pool5(F.relu(self.conv13(x)))\n",
    "        \n",
    "        x = x.view(-1,512*7*7)\n",
    "        x = F.relu(self.fc1(F.dropout(x,p=0.5)))\n",
    "        x = F.relu(self.fc2(F.dropout(x,p=0.5)))\n",
    "        output = F.softmax(self.fc3(x),dim=1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "vgg = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG16                                    --                        --\n",
       "├─Conv2d: 1-1                            [10, 64, 224, 224]        1,792\n",
       "├─Conv2d: 1-2                            [10, 64, 224, 224]        36,928\n",
       "├─MaxPool2d: 1-3                         [10, 64, 112, 112]        --\n",
       "├─Conv2d: 1-4                            [10, 128, 112, 112]       73,856\n",
       "├─Conv2d: 1-5                            [10, 128, 112, 112]       147,584\n",
       "├─MaxPool2d: 1-6                         [10, 128, 56, 56]         --\n",
       "├─Conv2d: 1-7                            [10, 256, 56, 56]         295,168\n",
       "├─Conv2d: 1-8                            [10, 256, 56, 56]         590,080\n",
       "├─Conv2d: 1-9                            [10, 256, 56, 56]         590,080\n",
       "├─MaxPool2d: 1-10                        [10, 256, 28, 28]         --\n",
       "├─Conv2d: 1-11                           [10, 512, 28, 28]         1,180,160\n",
       "├─Conv2d: 1-12                           [10, 512, 28, 28]         2,359,808\n",
       "├─Conv2d: 1-13                           [10, 512, 28, 28]         2,359,808\n",
       "├─MaxPool2d: 1-14                        [10, 512, 14, 14]         --\n",
       "├─Conv2d: 1-15                           [10, 512, 14, 14]         2,359,808\n",
       "├─Conv2d: 1-16                           [10, 512, 14, 14]         2,359,808\n",
       "├─Conv2d: 1-17                           [10, 512, 14, 14]         2,359,808\n",
       "├─MaxPool2d: 1-18                        [10, 512, 7, 7]           --\n",
       "├─Linear: 1-19                           [10, 4096]                102,764,544\n",
       "├─Linear: 1-20                           [10, 4096]                16,781,312\n",
       "├─Linear: 1-21                           [10, 10]                  40,970\n",
       "==========================================================================================\n",
       "Total params: 134,301,514\n",
       "Trainable params: 134,301,514\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 154.80\n",
       "==========================================================================================\n",
       "Input size (MB): 6.02\n",
       "Forward/backward pass size (MB): 1084.46\n",
       "Params size (MB): 537.21\n",
       "Estimated Total Size (MB): 1627.68\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(vgg,input_size=(10,3,224,224),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
