{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jupyter初始化过程中自动加载常用包的设置方法\n",
    "- 找`startup`文件夹\n",
    "用户主目录下找到`.ipython/profile_default/startup/`\n",
    "如果没有startup文件夹则新建一个\n",
    "- 创建`start.py`文件\n",
    "在`startup`文件夹内创建`start.py`文件\n",
    "- 在`start.py`文件内写入初始化时要`import`的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(features,labels,rate=0.7):\n",
    "    \"\"\"训练集和测试集切分\n",
    "    \n",
    "    params features: 输入的特征张量\n",
    "    params labels: 输入的标签张量\n",
    "    params rate: 训练集占所有 数据的比例\n",
    "    return Xtrain,Xtest,ytrain,ytest: 返回特征张量的训练集以及标签张量的训练集、测试集、测试集，\n",
    "    \n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    num_examples = len(features) # 总数据量\n",
    "    indices = list(range(num_examples)) # 数据集行索引\n",
    "    random.shuffle(indices) # 乱序调整\n",
    "    num_train = int(num_examples * rate) # 训练集数量\n",
    "    indices_train = torch.tensor(indices[:num_train]) # 在已经乱序的前indices中挑出前num_train数量的索引值\n",
    "    indices_test = torch.tensor(indices[num_train:])\n",
    "    Xtrain = features[indices_train] # 训练集特征\n",
    "    ytrain = labels[indices_train] # 训练集标签\n",
    "    Xtest = features[indices_test] # 测试集特征\n",
    "    ytest = labels[indices_test] # 测试集标签\n",
    "    \n",
    "    return Xtrain,Xtest,ytrain,ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "f = torch.arange(10)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.arange(1,11)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 7, 2, 4, 9, 3, 6]),\n",
       " tensor([1, 5, 8]),\n",
       " tensor([ 1,  8,  3,  5, 10,  4,  7]),\n",
       " tensor([2, 6, 9]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split(f,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的包\n",
    "\n",
    "# 随机模块\n",
    "import random\n",
    "\n",
    "# 绘图模块\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.nn import MSELoss # class\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 导入自定义模块\n",
    "from torchLearning import *\n",
    "\n",
    "# 导入以下包从而使得可以在 jupyter 中的 cell 输出多个结果\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbe3e474210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "\n",
    "features,labels = tensorGenReg()\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = data_split(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([700, 3]),\n",
       " torch.Size([300, 3]),\n",
       " torch.Size([700, 1]),\n",
       " torch.Size([300, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape,Xtest.shape,ytrain.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化核心参数\n",
    "batch_size = 10\n",
    "lr = 0.03\n",
    "num_epochs = 5\n",
    "w = torch.zeros(3,1,requires_grad=True)\n",
    "\n",
    "# 参与训练的模型参数\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "# 模型训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter(batch_size,Xtrain,ytrain):\n",
    "        l = loss(net(X,w),y)\n",
    "        l.backward()\n",
    "        sgd(w,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0004],\n",
       "        [-1.0010],\n",
       "        [ 1.0008]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_loss(torch.mm(Xtrain,w),ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.7553e-05, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_loss(torch.mm(Xtest,w),ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch中的切分数据不是复制切分数据存储，而是逻辑关系上（数据存储地址）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 和 DataLoader的基本使用方法和数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(12).reshape(4,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x7fbe4040fee0>,\n",
       " <torch.utils.data.dataset.Subset at 0x7fbe4040ff40>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_split(t,[2,2]) # 输入切分的每部分数据集数量\n",
    "# params1: 切分的 数据tensor\n",
    "# params2: [2,2] 切分为两份，分别两条数据 [6,4] 切分为两份，第一份6个，第二份4个\n",
    "# random_split 函数其实生成了 生成器切分结果的 生成器，并不是切分数据后返回。这符合utils.data模块主要生成映射式和迭代对象的一般规定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_split(t,[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 10, 11]) tensor([0, 1, 2])\n",
      "tensor([3, 4, 5]) tensor([6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "for tr,te in random_split(t,[2,2]):\n",
    "    print(tr,te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer as LBC # 导入乳腺癌数据\n",
    "data = LBC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data # 返回数据集的特征数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target # 返回数据集的标签数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.data) # 返回数据集总个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBCDataset(Dataset):\n",
    "    def __init__(self,data): # 创建该类时需要输入sklearn导入的数据集\n",
    "        self.features = data.data # features属性返回数据集特征\n",
    "        self.labels = data.target # labels属性返回数据集标签\n",
    "        self.lens = len(data.data) # lens属性返回数据集大小\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # 调用该方法时需要输入index数值，方法最终返回index对应的特征和标签\n",
    "        return self.features[index,:],self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 调用该方法不需要输入额外参数，方法最终返回数据集大小\n",
    "        return self.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LBC()\n",
    "LBC_data = LBCDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]),\n",
       " 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.__getitem__(2) # 查看第3条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "       1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "       4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "       2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "       1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]),\n",
       " 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data[2] # 封装好的数据可以直接进行索引，并且能够返回实体结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data[:] # 所有数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用random_split方法对其进行切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(LBC_data.lens * 0.7)\n",
    "num_test = LBC_data.lens - num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train\n",
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBC_train,LBC_test = random_split(LBC_data,[num_train,num_test])\n",
    "\n",
    "# 此时切分的结果是一个映射式的对象，只有dataset 和 indices 两个属性，\n",
    "# 其中dataset属性用于查看数据集对象，\n",
    "# indices属性用于查看切分后数据集的每一条数据的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        Subset\n",
       "\u001b[0;31mString form:\u001b[0m <torch.utils.data.dataset.Subset object at 0x7fbe41b8fb80>\n",
       "\u001b[0;31mLength:\u001b[0m      398\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Subset of a dataset at specified indices.\n",
       "\n",
       "Arguments:\n",
       "    dataset (Dataset): The whole Dataset\n",
       "    indices (sequence): Indices in the whole set selected for subset\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LBC_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LBCDataset at 0x7fbe4040f280>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.dataset == LBC_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[423,\n",
       " 192,\n",
       " 83,\n",
       " 149,\n",
       " 181,\n",
       " 295,\n",
       " 135,\n",
       " 469,\n",
       " 93,\n",
       " 257,\n",
       " 341,\n",
       " 168,\n",
       " 164,\n",
       " 26,\n",
       " 381,\n",
       " 299,\n",
       " 380,\n",
       " 274,\n",
       " 100,\n",
       " 563,\n",
       " 65,\n",
       " 61,\n",
       " 71,\n",
       " 29,\n",
       " 86,\n",
       " 157,\n",
       " 263,\n",
       " 67,\n",
       " 564,\n",
       " 139,\n",
       " 42,\n",
       " 554,\n",
       " 272,\n",
       " 143,\n",
       " 255,\n",
       " 101,\n",
       " 134,\n",
       " 220,\n",
       " 431,\n",
       " 522,\n",
       " 206,\n",
       " 271,\n",
       " 278,\n",
       " 294,\n",
       " 248,\n",
       " 525,\n",
       " 322,\n",
       " 9,\n",
       " 55,\n",
       " 163,\n",
       " 548,\n",
       " 302,\n",
       " 532,\n",
       " 438,\n",
       " 102,\n",
       " 96,\n",
       " 72,\n",
       " 396,\n",
       " 339,\n",
       " 420,\n",
       " 212,\n",
       " 285,\n",
       " 166,\n",
       " 186,\n",
       " 509,\n",
       " 340,\n",
       " 528,\n",
       " 242,\n",
       " 390,\n",
       " 362,\n",
       " 315,\n",
       " 347,\n",
       " 370,\n",
       " 191,\n",
       " 270,\n",
       " 27,\n",
       " 459,\n",
       " 279,\n",
       " 284,\n",
       " 489,\n",
       " 35,\n",
       " 467,\n",
       " 266,\n",
       " 519,\n",
       " 75,\n",
       " 524,\n",
       " 201,\n",
       " 208,\n",
       " 421,\n",
       " 111,\n",
       " 39,\n",
       " 145,\n",
       " 103,\n",
       " 48,\n",
       " 224,\n",
       " 218,\n",
       " 205,\n",
       " 481,\n",
       " 195,\n",
       " 54,\n",
       " 88,\n",
       " 385,\n",
       " 1,\n",
       " 73,\n",
       " 58,\n",
       " 393,\n",
       " 281,\n",
       " 258,\n",
       " 526,\n",
       " 31,\n",
       " 401,\n",
       " 487,\n",
       " 561,\n",
       " 433,\n",
       " 259,\n",
       " 170,\n",
       " 344,\n",
       " 404,\n",
       " 543,\n",
       " 13,\n",
       " 202,\n",
       " 425,\n",
       " 353,\n",
       " 44,\n",
       " 50,\n",
       " 245,\n",
       " 472,\n",
       " 151,\n",
       " 57,\n",
       " 368,\n",
       " 442,\n",
       " 4,\n",
       " 518,\n",
       " 64,\n",
       " 11,\n",
       " 418,\n",
       " 463,\n",
       " 280,\n",
       " 328,\n",
       " 108,\n",
       " 122,\n",
       " 323,\n",
       " 223,\n",
       " 529,\n",
       " 539,\n",
       " 84,\n",
       " 99,\n",
       " 372,\n",
       " 249,\n",
       " 209,\n",
       " 161,\n",
       " 403,\n",
       " 558,\n",
       " 34,\n",
       " 19,\n",
       " 483,\n",
       " 534,\n",
       " 28,\n",
       " 342,\n",
       " 38,\n",
       " 398,\n",
       " 565,\n",
       " 364,\n",
       " 480,\n",
       " 553,\n",
       " 51,\n",
       " 5,\n",
       " 535,\n",
       " 379,\n",
       " 549,\n",
       " 136,\n",
       " 289,\n",
       " 303,\n",
       " 464,\n",
       " 477,\n",
       " 371,\n",
       " 312,\n",
       " 109,\n",
       " 104,\n",
       " 488,\n",
       " 189,\n",
       " 25,\n",
       " 112,\n",
       " 177,\n",
       " 199,\n",
       " 409,\n",
       " 444,\n",
       " 60,\n",
       " 550,\n",
       " 200,\n",
       " 47,\n",
       " 87,\n",
       " 116,\n",
       " 183,\n",
       " 70,\n",
       " 378,\n",
       " 521,\n",
       " 234,\n",
       " 376,\n",
       " 336,\n",
       " 188,\n",
       " 358,\n",
       " 94,\n",
       " 466,\n",
       " 33,\n",
       " 357,\n",
       " 426,\n",
       " 121,\n",
       " 443,\n",
       " 300,\n",
       " 288,\n",
       " 76,\n",
       " 436,\n",
       " 137,\n",
       " 250,\n",
       " 351,\n",
       " 453,\n",
       " 412,\n",
       " 146,\n",
       " 260,\n",
       " 377,\n",
       " 106,\n",
       " 53,\n",
       " 473,\n",
       " 128,\n",
       " 413,\n",
       " 95,\n",
       " 12,\n",
       " 325,\n",
       " 298,\n",
       " 566,\n",
       " 265,\n",
       " 389,\n",
       " 304,\n",
       " 313,\n",
       " 338,\n",
       " 493,\n",
       " 557,\n",
       " 432,\n",
       " 238,\n",
       " 391,\n",
       " 411,\n",
       " 496,\n",
       " 24,\n",
       " 542,\n",
       " 261,\n",
       " 552,\n",
       " 228,\n",
       " 273,\n",
       " 213,\n",
       " 123,\n",
       " 397,\n",
       " 226,\n",
       " 52,\n",
       " 229,\n",
       " 429,\n",
       " 267,\n",
       " 283,\n",
       " 74,\n",
       " 153,\n",
       " 332,\n",
       " 141,\n",
       " 399,\n",
       " 277,\n",
       " 32,\n",
       " 160,\n",
       " 369,\n",
       " 461,\n",
       " 416,\n",
       " 37,\n",
       " 476,\n",
       " 36,\n",
       " 187,\n",
       " 125,\n",
       " 144,\n",
       " 457,\n",
       " 148,\n",
       " 178,\n",
       " 511,\n",
       " 405,\n",
       " 90,\n",
       " 386,\n",
       " 105,\n",
       " 533,\n",
       " 374,\n",
       " 447,\n",
       " 275,\n",
       " 491,\n",
       " 555,\n",
       " 182,\n",
       " 445,\n",
       " 196,\n",
       " 114,\n",
       " 184,\n",
       " 343,\n",
       " 375,\n",
       " 247,\n",
       " 424,\n",
       " 546,\n",
       " 568,\n",
       " 355,\n",
       " 329,\n",
       " 482,\n",
       " 392,\n",
       " 256,\n",
       " 382,\n",
       " 415,\n",
       " 59,\n",
       " 150,\n",
       " 107,\n",
       " 126,\n",
       " 383,\n",
       " 448,\n",
       " 547,\n",
       " 516,\n",
       " 91,\n",
       " 479,\n",
       " 80,\n",
       " 179,\n",
       " 40,\n",
       " 152,\n",
       " 296,\n",
       " 236,\n",
       " 334,\n",
       " 402,\n",
       " 495,\n",
       " 46,\n",
       " 30,\n",
       " 349,\n",
       " 45,\n",
       " 498,\n",
       " 198,\n",
       " 269,\n",
       " 92,\n",
       " 363,\n",
       " 451,\n",
       " 133,\n",
       " 190,\n",
       " 194,\n",
       " 197,\n",
       " 503,\n",
       " 185,\n",
       " 348,\n",
       " 506,\n",
       " 301,\n",
       " 120,\n",
       " 545,\n",
       " 486,\n",
       " 311,\n",
       " 422,\n",
       " 89,\n",
       " 430,\n",
       " 21,\n",
       " 501,\n",
       " 435,\n",
       " 527,\n",
       " 225,\n",
       " 408,\n",
       " 97,\n",
       " 367,\n",
       " 240,\n",
       " 246,\n",
       " 536,\n",
       " 427,\n",
       " 287,\n",
       " 330,\n",
       " 446,\n",
       " 62,\n",
       " 455,\n",
       " 2,\n",
       " 320,\n",
       " 507,\n",
       " 3,\n",
       " 407,\n",
       " 132,\n",
       " 395,\n",
       " 56,\n",
       " 331,\n",
       " 514,\n",
       " 452,\n",
       " 291,\n",
       " 544,\n",
       " 22,\n",
       " 308,\n",
       " 175,\n",
       " 560,\n",
       " 203,\n",
       " 373,\n",
       " 450,\n",
       " 156,\n",
       " 230,\n",
       " 214,\n",
       " 326,\n",
       " 456,\n",
       " 297,\n",
       " 567,\n",
       " 155,\n",
       " 359]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.366e+01, 1.913e+01, 8.946e+01, 5.753e+02, 9.057e-02, 1.147e-01,\n",
      "       9.657e-02, 4.812e-02, 1.848e-01, 6.181e-02, 2.244e-01, 8.950e-01,\n",
      "       1.804e+00, 1.936e+01, 3.980e-03, 2.809e-02, 3.669e-02, 1.274e-02,\n",
      "       1.581e-02, 3.956e-03, 1.514e+01, 2.550e+01, 1.014e+02, 7.088e+02,\n",
      "       1.147e-01, 3.167e-01, 3.660e-01, 1.407e-01, 2.744e-01, 8.839e-02]), 1)\n"
     ]
    }
   ],
   "source": [
    "for i in LBC_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整建模评估过程\n",
    "\n",
    "# 生成数据\n",
    "features,labels = tensorGenReg()\n",
    "features = features[:, :-1] # 删除最后全是1的列\n",
    "\n",
    "# 创建一个针对手动创建数据的数据类\n",
    "class GenData(Dataset):\n",
    "    def __init__(self,features,lables): # 创建该类时需要输入的数据集\n",
    "        self.features = features\n",
    "        self.labels  = labels\n",
    "        self.lens = len(features)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.features[index,:],self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.lens\n",
    "    \n",
    "# 实例化对象\n",
    "data = GenData(features,labels)\n",
    "\n",
    "# 切分数据集\n",
    "num_train = int(data.lens * 0.7)\n",
    "num_test = data.lens - num_train\n",
    "data_train,data_test = random_split(data,[num_train,num_test])\n",
    "\n",
    "# 加载数据\n",
    "train_loader = DataLoader(data_train,batch_size=10,shuffle=True)\n",
    "test_loader = DataLoader(data_test,batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "\n",
    "# 初始化核心参数\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "lr = 0.03\n",
    "\n",
    "# Stage 1. 定义模型\n",
    "\n",
    "class LR(nn.Module):\n",
    "    # 定义模型点线结构\n",
    "    def __init__(self,in_features=2,out_features=1):\n",
    "        super(LR,self).__init__()\n",
    "        self.linear = nn.Linear(in_features,out_features)\n",
    "    \n",
    "    # 定义模型正向传播规则   \n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "# 实例化模型\n",
    "LR_model = LR()\n",
    "\n",
    "# Stage 2. 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Stage 3. 定义优化方法\n",
    "optimizer = optim.SGD(LR_model.parameters(),lr = lr)\n",
    "\n",
    "# Stage 4. 模型训练与测试\n",
    "def fit(net,criterion,optimizer,batchData,epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        for X,y in batchData:\n",
    "            yhat = net.forward(X)\n",
    "            loss = criterion(yhat,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练与测试\n",
    "\n",
    "fit(net = LR_model,\n",
    "   criterion = criterion,\n",
    "   optimizer = optimizer,\n",
    "   batchData = train_loader,\n",
    "   epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR(\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练模型\n",
    "LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.0001, -1.0002]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9997], requires_grad=True)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型参数\n",
    "list(LR_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看模型在训练集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[707,\n",
       " 931,\n",
       " 304,\n",
       " 695,\n",
       " 640,\n",
       " 13,\n",
       " 932,\n",
       " 353,\n",
       " 493,\n",
       " 964,\n",
       " 685,\n",
       " 154,\n",
       " 433,\n",
       " 77,\n",
       " 960,\n",
       " 635,\n",
       " 509,\n",
       " 262,\n",
       " 514,\n",
       " 278,\n",
       " 987,\n",
       " 28,\n",
       " 425,\n",
       " 683,\n",
       " 274,\n",
       " 427,\n",
       " 639,\n",
       " 596,\n",
       " 550,\n",
       " 763,\n",
       " 978,\n",
       " 422,\n",
       " 779,\n",
       " 543,\n",
       " 122,\n",
       " 775,\n",
       " 866,\n",
       " 519,\n",
       " 347,\n",
       " 50,\n",
       " 8,\n",
       " 911,\n",
       " 309,\n",
       " 990,\n",
       " 251,\n",
       " 874,\n",
       " 754,\n",
       " 557,\n",
       " 791,\n",
       " 548,\n",
       " 474,\n",
       " 55,\n",
       " 187,\n",
       " 121,\n",
       " 783,\n",
       " 730,\n",
       " 159,\n",
       " 469,\n",
       " 115,\n",
       " 376,\n",
       " 343,\n",
       " 183,\n",
       " 653,\n",
       " 500,\n",
       " 141,\n",
       " 487,\n",
       " 577,\n",
       " 149,\n",
       " 169,\n",
       " 655,\n",
       " 605,\n",
       " 310,\n",
       " 511,\n",
       " 455,\n",
       " 714,\n",
       " 586,\n",
       " 504,\n",
       " 542,\n",
       " 818,\n",
       " 464,\n",
       " 821,\n",
       " 746,\n",
       " 555,\n",
       " 74,\n",
       " 463,\n",
       " 982,\n",
       " 494,\n",
       " 79,\n",
       " 189,\n",
       " 563,\n",
       " 980,\n",
       " 197,\n",
       " 170,\n",
       " 43,\n",
       " 80,\n",
       " 684,\n",
       " 850,\n",
       " 109,\n",
       " 14,\n",
       " 993,\n",
       " 81,\n",
       " 380,\n",
       " 153,\n",
       " 317,\n",
       " 287,\n",
       " 868,\n",
       " 995,\n",
       " 67,\n",
       " 424,\n",
       " 253,\n",
       " 949,\n",
       " 742,\n",
       " 152,\n",
       " 299,\n",
       " 62,\n",
       " 607,\n",
       " 590,\n",
       " 56,\n",
       " 471,\n",
       " 429,\n",
       " 404,\n",
       " 693,\n",
       " 100,\n",
       " 751,\n",
       " 887,\n",
       " 218,\n",
       " 324,\n",
       " 131,\n",
       " 954,\n",
       " 381,\n",
       " 689,\n",
       " 132,\n",
       " 151,\n",
       " 194,\n",
       " 286,\n",
       " 580,\n",
       " 198,\n",
       " 892,\n",
       " 441,\n",
       " 745,\n",
       " 510,\n",
       " 454,\n",
       " 275,\n",
       " 623,\n",
       " 396,\n",
       " 162,\n",
       " 762,\n",
       " 551,\n",
       " 42,\n",
       " 836,\n",
       " 657,\n",
       " 857,\n",
       " 674,\n",
       " 498,\n",
       " 582,\n",
       " 407,\n",
       " 389,\n",
       " 673,\n",
       " 811,\n",
       " 790,\n",
       " 700,\n",
       " 967,\n",
       " 432,\n",
       " 89,\n",
       " 459,\n",
       " 382,\n",
       " 810,\n",
       " 138,\n",
       " 827,\n",
       " 482,\n",
       " 965,\n",
       " 989,\n",
       " 292,\n",
       " 180,\n",
       " 901,\n",
       " 799,\n",
       " 659,\n",
       " 852,\n",
       " 27,\n",
       " 728,\n",
       " 588,\n",
       " 820,\n",
       " 51,\n",
       " 357,\n",
       " 647,\n",
       " 148,\n",
       " 23,\n",
       " 501,\n",
       " 369,\n",
       " 512,\n",
       " 261,\n",
       " 248,\n",
       " 3,\n",
       " 854,\n",
       " 108,\n",
       " 94,\n",
       " 457,\n",
       " 245,\n",
       " 718,\n",
       " 869,\n",
       " 54,\n",
       " 748,\n",
       " 213,\n",
       " 860,\n",
       " 452,\n",
       " 959,\n",
       " 701,\n",
       " 311,\n",
       " 916,\n",
       " 260,\n",
       " 285,\n",
       " 634,\n",
       " 803,\n",
       " 570,\n",
       " 47,\n",
       " 155,\n",
       " 244,\n",
       " 211,\n",
       " 883,\n",
       " 919,\n",
       " 252,\n",
       " 168,\n",
       " 947,\n",
       " 63,\n",
       " 91,\n",
       " 777,\n",
       " 290,\n",
       " 315,\n",
       " 953,\n",
       " 572,\n",
       " 30,\n",
       " 21,\n",
       " 431,\n",
       " 679,\n",
       " 593,\n",
       " 339,\n",
       " 223,\n",
       " 296,\n",
       " 971,\n",
       " 842,\n",
       " 526,\n",
       " 591,\n",
       " 426,\n",
       " 794,\n",
       " 269,\n",
       " 340,\n",
       " 849,\n",
       " 583,\n",
       " 910,\n",
       " 798,\n",
       " 841,\n",
       " 846,\n",
       " 341,\n",
       " 739,\n",
       " 621,\n",
       " 166,\n",
       " 776,\n",
       " 772,\n",
       " 731,\n",
       " 32,\n",
       " 984,\n",
       " 969,\n",
       " 385,\n",
       " 68,\n",
       " 894,\n",
       " 536,\n",
       " 506,\n",
       " 893,\n",
       " 207,\n",
       " 630,\n",
       " 281,\n",
       " 215,\n",
       " 637,\n",
       " 732,\n",
       " 302,\n",
       " 239,\n",
       " 350,\n",
       " 489,\n",
       " 933,\n",
       " 358,\n",
       " 405,\n",
       " 508,\n",
       " 249,\n",
       " 703,\n",
       " 379,\n",
       " 356,\n",
       " 421,\n",
       " 663,\n",
       " 297,\n",
       " 254,\n",
       " 564,\n",
       " 461,\n",
       " 562,\n",
       " 886,\n",
       " 438,\n",
       " 393,\n",
       " 618,\n",
       " 24,\n",
       " 125,\n",
       " 992,\n",
       " 864,\n",
       " 283,\n",
       " 453,\n",
       " 33,\n",
       " 467,\n",
       " 360,\n",
       " 225,\n",
       " 212,\n",
       " 156,\n",
       " 52,\n",
       " 93,\n",
       " 265,\n",
       " 983,\n",
       " 727,\n",
       " 973,\n",
       " 725,\n",
       " 835,\n",
       " 365,\n",
       " 234,\n",
       " 875,\n",
       " 757,\n",
       " 899,\n",
       " 333,\n",
       " 288,\n",
       " 359,\n",
       " 876,\n",
       " 574,\n",
       " 729,\n",
       " 472,\n",
       " 915,\n",
       " 214,\n",
       " 191,\n",
       " 907,\n",
       " 362,\n",
       " 105,\n",
       " 610,\n",
       " 263,\n",
       " 968,\n",
       " 442,\n",
       " 371,\n",
       " 164,\n",
       " 416,\n",
       " 478,\n",
       " 617,\n",
       " 997,\n",
       " 217,\n",
       " 401,\n",
       " 773,\n",
       " 65,\n",
       " 581,\n",
       " 549,\n",
       " 48,\n",
       " 943,\n",
       " 130,\n",
       " 97,\n",
       " 412,\n",
       " 475,\n",
       " 545,\n",
       " 851,\n",
       " 280,\n",
       " 157,\n",
       " 276,\n",
       " 979,\n",
       " 584,\n",
       " 855,\n",
       " 232,\n",
       " 444,\n",
       " 120,\n",
       " 53,\n",
       " 948,\n",
       " 37,\n",
       " 488,\n",
       " 397,\n",
       " 57,\n",
       " 497,\n",
       " 770,\n",
       " 220,\n",
       " 897,\n",
       " 665,\n",
       " 633,\n",
       " 687,\n",
       " 163,\n",
       " 307,\n",
       " 998,\n",
       " 354,\n",
       " 780,\n",
       " 420,\n",
       " 78,\n",
       " 414,\n",
       " 305,\n",
       " 908,\n",
       " 904,\n",
       " 395,\n",
       " 167,\n",
       " 399,\n",
       " 31,\n",
       " 767,\n",
       " 127,\n",
       " 195,\n",
       " 604,\n",
       " 468,\n",
       " 110,\n",
       " 46,\n",
       " 737,\n",
       " 181,\n",
       " 884,\n",
       " 929,\n",
       " 268,\n",
       " 99,\n",
       " 516,\n",
       " 451,\n",
       " 240,\n",
       " 520,\n",
       " 667,\n",
       " 848,\n",
       " 692,\n",
       " 112,\n",
       " 301,\n",
       " 752,\n",
       " 565,\n",
       " 72,\n",
       " 698,\n",
       " 344,\n",
       " 853,\n",
       " 113,\n",
       " 76,\n",
       " 938,\n",
       " 822,\n",
       " 598,\n",
       " 662,\n",
       " 600,\n",
       " 981,\n",
       " 862,\n",
       " 756,\n",
       " 499,\n",
       " 962,\n",
       " 338,\n",
       " 204,\n",
       " 476,\n",
       " 691,\n",
       " 363,\n",
       " 942,\n",
       " 644,\n",
       " 579,\n",
       " 627,\n",
       " 676,\n",
       " 819,\n",
       " 815,\n",
       " 926,\n",
       " 985,\n",
       " 1,\n",
       " 505,\n",
       " 41,\n",
       " 975,\n",
       " 533,\n",
       " 920,\n",
       " 758,\n",
       " 450,\n",
       " 888,\n",
       " 5,\n",
       " 749,\n",
       " 70,\n",
       " 479,\n",
       " 606,\n",
       " 20,\n",
       " 327,\n",
       " 199,\n",
       " 219,\n",
       " 826,\n",
       " 809,\n",
       " 923,\n",
       " 342,\n",
       " 73,\n",
       " 966,\n",
       " 29,\n",
       " 85,\n",
       " 861,\n",
       " 527,\n",
       " 743,\n",
       " 847,\n",
       " 177,\n",
       " 95,\n",
       " 753,\n",
       " 300,\n",
       " 696,\n",
       " 797,\n",
       " 805,\n",
       " 567,\n",
       " 787,\n",
       " 702,\n",
       " 134,\n",
       " 686,\n",
       " 768,\n",
       " 870,\n",
       " 367,\n",
       " 537,\n",
       " 628,\n",
       " 413,\n",
       " 370,\n",
       " 503,\n",
       " 326,\n",
       " 716,\n",
       " 111,\n",
       " 622,\n",
       " 814,\n",
       " 38,\n",
       " 540,\n",
       " 945,\n",
       " 147,\n",
       " 940,\n",
       " 403,\n",
       " 648,\n",
       " 678,\n",
       " 534,\n",
       " 539,\n",
       " 649,\n",
       " 722,\n",
       " 576,\n",
       " 481,\n",
       " 638,\n",
       " 706,\n",
       " 602,\n",
       " 325,\n",
       " 524,\n",
       " 258,\n",
       " 765,\n",
       " 778,\n",
       " 631,\n",
       " 490,\n",
       " 129,\n",
       " 373,\n",
       " 878,\n",
       " 544,\n",
       " 585,\n",
       " 446,\n",
       " 525,\n",
       " 578,\n",
       " 477,\n",
       " 529,\n",
       " 462,\n",
       " 996,\n",
       " 556,\n",
       " 492,\n",
       " 49,\n",
       " 611,\n",
       " 216,\n",
       " 880,\n",
       " 434,\n",
       " 329,\n",
       " 891,\n",
       " 568,\n",
       " 173,\n",
       " 928,\n",
       " 267,\n",
       " 142,\n",
       " 61,\n",
       " 833,\n",
       " 319,\n",
       " 682,\n",
       " 781,\n",
       " 669,\n",
       " 970,\n",
       " 235,\n",
       " 726,\n",
       " 257,\n",
       " 323,\n",
       " 595,\n",
       " 974,\n",
       " 394,\n",
       " 361,\n",
       " 64,\n",
       " 186,\n",
       " 491,\n",
       " 196,\n",
       " 615,\n",
       " 760,\n",
       " 4,\n",
       " 123,\n",
       " 107,\n",
       " 736,\n",
       " 230,\n",
       " 436,\n",
       " 812,\n",
       " 654,\n",
       " 306,\n",
       " 352,\n",
       " 96,\n",
       " 36,\n",
       " 337,\n",
       " 817,\n",
       " 882,\n",
       " 594,\n",
       " 816,\n",
       " 128,\n",
       " 496,\n",
       " 955,\n",
       " 418,\n",
       " 881,\n",
       " 161,\n",
       " 172,\n",
       " 485,\n",
       " 795,\n",
       " 913,\n",
       " 58,\n",
       " 237,\n",
       " 188,\n",
       " 502,\n",
       " 45,\n",
       " 650,\n",
       " 419,\n",
       " 60,\n",
       " 206,\n",
       " 366,\n",
       " 104,\n",
       " 991,\n",
       " 133,\n",
       " 11,\n",
       " 16,\n",
       " 348,\n",
       " 377,\n",
       " 786,\n",
       " 902,\n",
       " 106,\n",
       " 119,\n",
       " 759,\n",
       " 538,\n",
       " 761,\n",
       " 313,\n",
       " 277,\n",
       " 999,\n",
       " 208,\n",
       " 466,\n",
       " 398,\n",
       " 26,\n",
       " 101,\n",
       " 681,\n",
       " 575,\n",
       " 375,\n",
       " 624,\n",
       " 771,\n",
       " 465,\n",
       " 608,\n",
       " 697,\n",
       " 856,\n",
       " 19,\n",
       " 738,\n",
       " 445,\n",
       " 92,\n",
       " 460,\n",
       " 785,\n",
       " 924,\n",
       " 905,\n",
       " 914,\n",
       " 203,\n",
       " 744,\n",
       " 448,\n",
       " 417,\n",
       " 400,\n",
       " 612,\n",
       " 17,\n",
       " 963,\n",
       " 944,\n",
       " 925,\n",
       " 705,\n",
       " 345,\n",
       " 331,\n",
       " 144,\n",
       " 12,\n",
       " 87,\n",
       " 7,\n",
       " 656,\n",
       " 800,\n",
       " 986,\n",
       " 449,\n",
       " 918,\n",
       " 660,\n",
       " 314,\n",
       " 2,\n",
       " 766,\n",
       " 619,\n",
       " 877,\n",
       " 937,\n",
       " 222,\n",
       " 723,\n",
       " 201,\n",
       " 652,\n",
       " 160,\n",
       " 35,\n",
       " 439,\n",
       " 176,\n",
       " 415,\n",
       " 930,\n",
       " 547,\n",
       " 322,\n",
       " 428,\n",
       " 126,\n",
       " 694,\n",
       " 458,\n",
       " 209,\n",
       " 174]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先使用dataset和indices方法，还原训练数据集\n",
    "data_train.indices # 返回训练集索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0566,  0.6108],\n",
       "         [-0.0324, -1.0479],\n",
       "         [-0.2432, -0.3873],\n",
       "         ...,\n",
       "         [-1.7935, -1.0075],\n",
       "         [ 0.5288, -0.1329],\n",
       "         [ 0.2610, -0.0919]]),\n",
       " tensor([[-1.7242e+00],\n",
       "         [ 1.9906e+00],\n",
       "         [ 8.9809e-01],\n",
       "         [ 1.2759e+00],\n",
       "         [-2.3948e+00],\n",
       "         [-1.5561e+00],\n",
       "         [-7.2017e-01],\n",
       "         [ 4.5488e+00],\n",
       "         [ 4.2594e+00],\n",
       "         [ 8.1584e-01],\n",
       "         [-9.2630e-01],\n",
       "         [ 2.5102e+00],\n",
       "         [ 4.6704e+00],\n",
       "         [ 9.2945e-01],\n",
       "         [ 1.7095e+00],\n",
       "         [-4.7393e-01],\n",
       "         [ 4.3947e+00],\n",
       "         [ 2.4332e+00],\n",
       "         [-2.1711e+00],\n",
       "         [ 3.5524e+00],\n",
       "         [-5.4729e-01],\n",
       "         [ 1.3865e+00],\n",
       "         [-2.7487e+00],\n",
       "         [-9.4334e-01],\n",
       "         [ 3.7239e+00],\n",
       "         [ 5.8758e+00],\n",
       "         [ 2.4333e+00],\n",
       "         [ 3.1600e+00],\n",
       "         [ 2.9291e+00],\n",
       "         [ 1.0294e+00],\n",
       "         [ 1.7596e+00],\n",
       "         [-1.2694e+00],\n",
       "         [ 2.8442e+00],\n",
       "         [ 1.2511e+00],\n",
       "         [ 3.0783e+00],\n",
       "         [-1.6820e+00],\n",
       "         [-1.4034e-01],\n",
       "         [ 1.4491e+00],\n",
       "         [ 6.9132e+00],\n",
       "         [-2.6006e+00],\n",
       "         [ 3.0392e+00],\n",
       "         [ 4.4775e+00],\n",
       "         [ 3.5745e+00],\n",
       "         [ 3.3593e+00],\n",
       "         [ 1.4579e-02],\n",
       "         [ 9.7327e-01],\n",
       "         [ 1.0384e+00],\n",
       "         [ 2.2549e+00],\n",
       "         [ 1.1831e+00],\n",
       "         [ 4.7393e+00],\n",
       "         [ 6.4865e-01],\n",
       "         [ 1.4637e+00],\n",
       "         [-4.4818e+00],\n",
       "         [-2.4847e+00],\n",
       "         [ 2.6183e+00],\n",
       "         [-7.5075e-01],\n",
       "         [ 4.5460e+00],\n",
       "         [ 3.5405e+00],\n",
       "         [-1.5488e-01],\n",
       "         [-1.6886e+00],\n",
       "         [-3.4503e-01],\n",
       "         [ 1.0164e+00],\n",
       "         [ 2.0321e+00],\n",
       "         [ 5.6678e+00],\n",
       "         [-7.2529e-01],\n",
       "         [ 2.2973e-01],\n",
       "         [ 1.5775e-02],\n",
       "         [ 2.6750e+00],\n",
       "         [-1.9872e+00],\n",
       "         [ 4.3232e+00],\n",
       "         [-1.2392e+00],\n",
       "         [ 1.3480e+00],\n",
       "         [-1.8934e+00],\n",
       "         [-1.0573e+00],\n",
       "         [ 1.6009e+00],\n",
       "         [ 1.3286e+00],\n",
       "         [ 2.1212e+00],\n",
       "         [ 3.9018e+00],\n",
       "         [ 5.9037e+00],\n",
       "         [ 1.4930e-01],\n",
       "         [-6.0633e-01],\n",
       "         [ 1.3992e+00],\n",
       "         [-9.6012e-01],\n",
       "         [-2.1537e+00],\n",
       "         [ 1.1467e+00],\n",
       "         [ 2.2326e+00],\n",
       "         [ 3.6871e-01],\n",
       "         [ 5.0104e+00],\n",
       "         [ 8.1674e-01],\n",
       "         [ 3.8626e+00],\n",
       "         [ 3.5044e-02],\n",
       "         [ 1.9740e+00],\n",
       "         [ 2.6838e+00],\n",
       "         [ 1.8302e+00],\n",
       "         [ 5.0852e+00],\n",
       "         [-2.2171e-01],\n",
       "         [ 1.2175e+00],\n",
       "         [-5.1150e-01],\n",
       "         [-1.1415e+00],\n",
       "         [ 1.8500e+00],\n",
       "         [ 3.0358e+00],\n",
       "         [ 1.6566e+00],\n",
       "         [-1.6763e-03],\n",
       "         [ 5.8939e-01],\n",
       "         [ 5.7876e+00],\n",
       "         [ 4.4498e-01],\n",
       "         [-1.0359e-01],\n",
       "         [ 1.0838e+00],\n",
       "         [-1.8223e-01],\n",
       "         [ 5.8078e+00],\n",
       "         [ 4.6341e+00],\n",
       "         [-5.7408e-01],\n",
       "         [ 1.3012e-01],\n",
       "         [ 2.2770e+00],\n",
       "         [ 2.1071e+00],\n",
       "         [-1.4734e-01],\n",
       "         [-7.0402e-01],\n",
       "         [-1.2273e+00],\n",
       "         [-9.3414e-02],\n",
       "         [-2.4710e-01],\n",
       "         [ 4.2410e+00],\n",
       "         [ 5.8576e-01],\n",
       "         [ 1.6283e+00],\n",
       "         [ 1.4679e+00],\n",
       "         [-1.2652e+00],\n",
       "         [-1.6021e+00],\n",
       "         [ 1.5540e+00],\n",
       "         [ 3.5597e+00],\n",
       "         [-3.2117e-01],\n",
       "         [ 2.6761e+00],\n",
       "         [-3.9208e+00],\n",
       "         [ 1.0946e+00],\n",
       "         [ 3.8995e+00],\n",
       "         [ 1.7173e+00],\n",
       "         [ 4.2510e+00],\n",
       "         [-4.8871e-01],\n",
       "         [ 3.3129e+00],\n",
       "         [ 1.2696e+00],\n",
       "         [-1.6971e+00],\n",
       "         [-2.6140e+00],\n",
       "         [-3.3084e-01],\n",
       "         [ 7.8277e-01],\n",
       "         [ 5.5417e+00],\n",
       "         [-8.7483e-02],\n",
       "         [ 2.2114e-02],\n",
       "         [ 1.2391e-01],\n",
       "         [-1.3838e+00],\n",
       "         [ 3.1514e-01],\n",
       "         [-9.2004e-01],\n",
       "         [ 2.8535e+00],\n",
       "         [ 3.9416e-01],\n",
       "         [-4.5855e-01],\n",
       "         [ 8.2687e+00],\n",
       "         [ 1.3084e+00],\n",
       "         [ 5.3413e-01],\n",
       "         [ 2.1508e+00],\n",
       "         [ 3.4455e-01],\n",
       "         [-5.7929e-01],\n",
       "         [-3.6308e+00],\n",
       "         [ 1.8012e+00],\n",
       "         [-1.5384e+00],\n",
       "         [ 3.0720e+00],\n",
       "         [ 3.7025e-01],\n",
       "         [ 1.3103e+00],\n",
       "         [ 2.0009e+00],\n",
       "         [ 1.3301e+00],\n",
       "         [ 3.3236e+00],\n",
       "         [-8.5463e-01],\n",
       "         [ 2.1776e+00],\n",
       "         [-2.7079e-02],\n",
       "         [ 1.0654e+00],\n",
       "         [-1.9964e+00],\n",
       "         [ 4.5894e+00],\n",
       "         [ 3.5952e+00],\n",
       "         [ 6.2374e-01],\n",
       "         [-3.0334e+00],\n",
       "         [ 4.0428e-02],\n",
       "         [ 7.6724e+00],\n",
       "         [ 2.0895e+00],\n",
       "         [ 5.0015e+00],\n",
       "         [ 3.1587e+00],\n",
       "         [ 5.0241e+00],\n",
       "         [ 8.0861e-01],\n",
       "         [ 3.3622e+00],\n",
       "         [ 2.8193e+00],\n",
       "         [-3.2377e+00],\n",
       "         [-3.1279e+00],\n",
       "         [ 2.7673e+00],\n",
       "         [ 2.5464e+00],\n",
       "         [ 5.1807e-01],\n",
       "         [ 1.7671e+00],\n",
       "         [-2.6155e+00],\n",
       "         [-6.5292e-01],\n",
       "         [ 1.8133e+00],\n",
       "         [-6.2573e-01],\n",
       "         [ 4.8279e+00],\n",
       "         [ 1.8926e+00],\n",
       "         [-9.6861e-01],\n",
       "         [-1.7054e+00],\n",
       "         [ 3.2909e+00],\n",
       "         [ 2.8422e+00],\n",
       "         [ 6.9039e-01],\n",
       "         [ 2.2732e+00],\n",
       "         [ 3.9634e+00],\n",
       "         [ 3.5938e+00],\n",
       "         [ 3.4842e+00],\n",
       "         [ 9.6808e-01],\n",
       "         [ 6.2712e-01],\n",
       "         [-2.2791e-02],\n",
       "         [-1.4715e-01],\n",
       "         [ 1.5693e+00],\n",
       "         [-2.8588e-01],\n",
       "         [ 2.9754e-01],\n",
       "         [ 6.6249e-01],\n",
       "         [-7.7957e-01],\n",
       "         [-7.0432e-01],\n",
       "         [-1.0389e-02],\n",
       "         [-3.5236e-01],\n",
       "         [ 2.1542e+00],\n",
       "         [ 1.3791e+00],\n",
       "         [ 9.7546e-01],\n",
       "         [ 4.5128e+00],\n",
       "         [-9.2614e-01],\n",
       "         [ 1.6004e+00],\n",
       "         [ 2.7802e+00],\n",
       "         [ 1.7572e+00],\n",
       "         [ 1.2976e+00],\n",
       "         [ 8.7313e-01],\n",
       "         [ 1.2233e+00],\n",
       "         [-3.7966e-01],\n",
       "         [ 1.7043e+00],\n",
       "         [ 1.6037e+00],\n",
       "         [ 1.7542e+00],\n",
       "         [-9.3105e-01],\n",
       "         [ 1.8288e+00],\n",
       "         [ 8.3229e-01],\n",
       "         [ 2.4070e+00],\n",
       "         [ 2.4701e+00],\n",
       "         [ 5.0539e-01],\n",
       "         [ 2.8538e+00],\n",
       "         [-2.2956e-01],\n",
       "         [-1.2743e+00],\n",
       "         [ 1.0238e+00],\n",
       "         [ 2.8569e+00],\n",
       "         [-9.7844e-01],\n",
       "         [-4.6257e-02],\n",
       "         [-6.3674e-01],\n",
       "         [-6.7785e-01],\n",
       "         [ 3.2694e+00],\n",
       "         [-1.0884e+00],\n",
       "         [ 5.3677e-02],\n",
       "         [ 4.4051e-01],\n",
       "         [ 1.6960e-01],\n",
       "         [ 2.8811e+00],\n",
       "         [-5.8806e-01],\n",
       "         [ 2.4077e+00],\n",
       "         [-1.9908e+00],\n",
       "         [ 5.4025e+00],\n",
       "         [ 7.2056e-01],\n",
       "         [-8.4485e-01],\n",
       "         [-2.0178e-02],\n",
       "         [-1.3752e+00],\n",
       "         [-3.8884e-02],\n",
       "         [ 7.5282e+00],\n",
       "         [ 2.9584e+00],\n",
       "         [-1.2594e+00],\n",
       "         [ 1.7296e+00],\n",
       "         [ 2.2397e+00],\n",
       "         [-3.5526e-01],\n",
       "         [-3.5033e-01],\n",
       "         [-2.9015e-01],\n",
       "         [ 3.1800e+00],\n",
       "         [-2.7083e-01],\n",
       "         [ 3.1710e+00],\n",
       "         [ 1.2296e+00],\n",
       "         [ 2.4909e+00],\n",
       "         [ 3.2264e+00],\n",
       "         [-8.9776e-02],\n",
       "         [-9.9010e-01],\n",
       "         [ 1.6356e+00],\n",
       "         [-3.7021e-02],\n",
       "         [-1.8642e+00],\n",
       "         [ 1.1447e+00],\n",
       "         [-6.8298e-01],\n",
       "         [ 5.0756e+00],\n",
       "         [ 1.3042e+00],\n",
       "         [ 2.8666e+00],\n",
       "         [-2.9307e+00],\n",
       "         [ 2.7584e+00],\n",
       "         [-3.3334e+00],\n",
       "         [ 5.6341e+00],\n",
       "         [ 3.9566e+00],\n",
       "         [ 9.5212e-01],\n",
       "         [-1.1835e+00],\n",
       "         [ 1.2180e+00],\n",
       "         [ 4.2396e+00],\n",
       "         [ 9.3689e-01],\n",
       "         [ 2.1568e+00],\n",
       "         [ 1.1084e+00],\n",
       "         [ 4.4373e-01],\n",
       "         [ 6.7077e+00],\n",
       "         [ 4.5401e-01],\n",
       "         [-1.0226e+00],\n",
       "         [ 3.0681e+00],\n",
       "         [-2.5937e+00],\n",
       "         [ 7.3393e+00],\n",
       "         [-3.9400e-01],\n",
       "         [-9.5489e-02],\n",
       "         [ 1.7746e+00],\n",
       "         [-2.3952e+00],\n",
       "         [ 3.9296e+00],\n",
       "         [-1.9135e+00],\n",
       "         [-1.6163e+00],\n",
       "         [ 2.3781e+00],\n",
       "         [ 2.1463e+00],\n",
       "         [-4.6586e-01],\n",
       "         [ 4.2706e+00],\n",
       "         [ 5.0479e+00],\n",
       "         [ 5.6536e-02],\n",
       "         [ 1.7203e+00],\n",
       "         [ 1.0073e-01],\n",
       "         [ 3.7302e+00],\n",
       "         [ 3.6783e+00],\n",
       "         [-3.5729e+00],\n",
       "         [-2.8786e-02],\n",
       "         [-9.6731e-01],\n",
       "         [ 1.4827e+00],\n",
       "         [ 2.8684e+00],\n",
       "         [ 1.0145e+00],\n",
       "         [-1.6441e+00],\n",
       "         [ 3.6937e+00],\n",
       "         [-1.5882e+00],\n",
       "         [-3.1739e+00],\n",
       "         [ 1.4261e+00],\n",
       "         [ 1.7622e+00],\n",
       "         [-1.8815e-01],\n",
       "         [ 1.4078e+00],\n",
       "         [ 1.6770e+00],\n",
       "         [ 7.4249e-01],\n",
       "         [ 2.8213e-01],\n",
       "         [ 3.0718e+00],\n",
       "         [-1.5578e+00],\n",
       "         [ 8.0909e-01],\n",
       "         [-1.7287e+00],\n",
       "         [ 1.7137e+00],\n",
       "         [ 1.7149e+00],\n",
       "         [ 3.2051e+00],\n",
       "         [-2.2794e+00],\n",
       "         [ 1.6736e+00],\n",
       "         [-2.6789e-01],\n",
       "         [ 6.2742e-01],\n",
       "         [ 1.5592e+00],\n",
       "         [ 7.6546e-01],\n",
       "         [ 2.8423e+00],\n",
       "         [ 5.4303e-02],\n",
       "         [-1.9782e-01],\n",
       "         [ 3.2846e+00],\n",
       "         [ 3.3073e+00],\n",
       "         [ 2.6697e+00],\n",
       "         [ 1.1187e+00],\n",
       "         [-1.2740e+00],\n",
       "         [-2.1028e+00],\n",
       "         [ 1.2094e+00],\n",
       "         [ 4.1673e+00],\n",
       "         [-1.9171e+00],\n",
       "         [-4.3300e+00],\n",
       "         [-4.6576e+00],\n",
       "         [-1.1086e+00],\n",
       "         [ 1.8609e+00],\n",
       "         [-1.4076e+00],\n",
       "         [ 4.3184e+00],\n",
       "         [-3.1446e-01],\n",
       "         [-7.1934e-01],\n",
       "         [-1.9384e+00],\n",
       "         [-3.3116e-01],\n",
       "         [ 7.4037e-01],\n",
       "         [ 1.7645e+00],\n",
       "         [ 2.2300e+00],\n",
       "         [ 8.8790e-01],\n",
       "         [ 1.1382e+00],\n",
       "         [ 2.4922e+00],\n",
       "         [ 3.6833e+00],\n",
       "         [ 1.5860e+00],\n",
       "         [ 1.6738e+00],\n",
       "         [ 2.4611e+00],\n",
       "         [-4.4866e-02],\n",
       "         [ 2.7707e+00],\n",
       "         [ 3.0999e+00],\n",
       "         [ 3.6161e+00],\n",
       "         [ 2.9358e-01],\n",
       "         [ 1.9431e+00],\n",
       "         [ 3.3634e+00],\n",
       "         [ 2.9084e+00],\n",
       "         [ 3.7748e+00],\n",
       "         [ 2.2985e+00],\n",
       "         [-4.1378e-01],\n",
       "         [-1.9486e+00],\n",
       "         [ 1.5172e+00],\n",
       "         [-7.8322e-01],\n",
       "         [ 7.0940e-01],\n",
       "         [-1.5577e-01],\n",
       "         [ 4.4349e+00],\n",
       "         [-3.6392e-01],\n",
       "         [ 5.7489e+00],\n",
       "         [-2.8950e+00],\n",
       "         [ 4.8877e+00],\n",
       "         [-1.7300e+00],\n",
       "         [-2.0000e-01],\n",
       "         [ 4.7310e+00],\n",
       "         [ 1.4677e+00],\n",
       "         [-4.1488e+00],\n",
       "         [-7.6871e-02],\n",
       "         [ 1.6226e+00],\n",
       "         [-1.4404e+00],\n",
       "         [-1.2390e-01],\n",
       "         [ 5.9083e-01],\n",
       "         [ 8.6993e-01],\n",
       "         [-1.9056e+00],\n",
       "         [-3.9656e-01],\n",
       "         [ 1.8498e+00],\n",
       "         [ 5.2702e+00],\n",
       "         [ 1.0386e+00],\n",
       "         [ 1.3202e+00],\n",
       "         [ 8.8960e-01],\n",
       "         [ 2.6626e-01],\n",
       "         [ 2.1519e+00],\n",
       "         [ 1.0016e+00],\n",
       "         [ 2.2679e+00],\n",
       "         [-1.2237e+00],\n",
       "         [-9.0587e-01],\n",
       "         [-1.5493e-01],\n",
       "         [ 2.4533e+00],\n",
       "         [ 1.0202e+00],\n",
       "         [ 2.8351e+00],\n",
       "         [-7.8084e-02],\n",
       "         [ 1.0914e+00],\n",
       "         [-3.1891e+00],\n",
       "         [ 1.0762e+00],\n",
       "         [ 6.7047e+00],\n",
       "         [-3.2196e+00],\n",
       "         [ 3.5021e+00],\n",
       "         [ 1.9747e+00],\n",
       "         [-3.0429e+00],\n",
       "         [ 3.7073e+00],\n",
       "         [ 4.1435e+00],\n",
       "         [-5.1173e+00],\n",
       "         [-2.0110e-01],\n",
       "         [-1.9617e+00],\n",
       "         [ 1.3412e+00],\n",
       "         [-1.4062e-01],\n",
       "         [ 1.0693e+00],\n",
       "         [ 2.3610e+00],\n",
       "         [-1.2937e+00],\n",
       "         [ 2.2944e+00],\n",
       "         [-4.9092e-01],\n",
       "         [ 9.9049e-01],\n",
       "         [ 2.9198e+00],\n",
       "         [ 3.8805e+00],\n",
       "         [ 1.1088e+00],\n",
       "         [-1.1949e+00],\n",
       "         [ 4.5618e+00],\n",
       "         [ 3.4055e+00],\n",
       "         [ 1.3031e+00],\n",
       "         [ 6.5030e+00],\n",
       "         [ 4.0066e+00],\n",
       "         [ 4.1410e-01],\n",
       "         [ 1.2299e+00],\n",
       "         [-2.6151e+00],\n",
       "         [-2.6584e+00],\n",
       "         [ 1.1808e+00],\n",
       "         [ 1.6413e+00],\n",
       "         [ 2.7243e+00],\n",
       "         [-2.1515e+00],\n",
       "         [-1.0495e+00],\n",
       "         [-3.0128e+00],\n",
       "         [-2.8566e+00],\n",
       "         [-1.0375e-01],\n",
       "         [ 2.5500e+00],\n",
       "         [-1.3748e+00],\n",
       "         [ 1.1813e+00],\n",
       "         [ 1.7682e+00],\n",
       "         [-1.4945e+00],\n",
       "         [ 3.3816e+00],\n",
       "         [ 3.0428e+00],\n",
       "         [ 6.3339e-01],\n",
       "         [ 4.5799e+00],\n",
       "         [-2.1584e-01],\n",
       "         [-5.1125e-01],\n",
       "         [ 4.5341e-01],\n",
       "         [ 1.3166e+00],\n",
       "         [-6.9279e-01],\n",
       "         [-1.3925e+00],\n",
       "         [-2.5062e+00],\n",
       "         [ 1.2129e+00],\n",
       "         [-9.6910e-01],\n",
       "         [ 4.8891e+00],\n",
       "         [-2.3280e-01],\n",
       "         [ 8.1472e-01],\n",
       "         [-3.5046e-01],\n",
       "         [ 6.7876e-01],\n",
       "         [ 9.2343e-01],\n",
       "         [ 7.0460e-01],\n",
       "         [ 1.9047e+00],\n",
       "         [ 1.8200e+00],\n",
       "         [-9.2851e-02],\n",
       "         [ 3.6959e+00],\n",
       "         [ 4.6004e-01],\n",
       "         [-3.1393e-01],\n",
       "         [-1.4895e+00],\n",
       "         [ 2.8412e-02],\n",
       "         [ 4.1166e+00],\n",
       "         [-2.2985e+00],\n",
       "         [-4.8273e-01],\n",
       "         [ 6.2501e+00],\n",
       "         [ 1.3368e+00],\n",
       "         [ 3.4229e+00],\n",
       "         [ 2.0821e+00],\n",
       "         [-1.6178e+00],\n",
       "         [ 1.1352e+00],\n",
       "         [ 2.0608e+00],\n",
       "         [ 2.0077e+00],\n",
       "         [ 4.3115e-01],\n",
       "         [ 1.3370e-02],\n",
       "         [ 1.6783e-01],\n",
       "         [ 5.1438e+00],\n",
       "         [-2.1522e+00],\n",
       "         [ 3.2740e+00],\n",
       "         [ 3.0965e+00],\n",
       "         [ 2.5487e+00],\n",
       "         [ 1.5657e+00],\n",
       "         [ 1.0547e+00],\n",
       "         [ 3.9085e+00],\n",
       "         [-2.5993e+00],\n",
       "         [-7.7921e-01],\n",
       "         [-5.7629e-01],\n",
       "         [ 6.3764e+00],\n",
       "         [-2.3906e+00],\n",
       "         [ 1.5388e-01],\n",
       "         [ 2.5620e-01],\n",
       "         [-9.4185e-01],\n",
       "         [ 2.5532e+00],\n",
       "         [ 3.7885e+00],\n",
       "         [ 3.4244e+00],\n",
       "         [ 3.6168e+00],\n",
       "         [ 1.4097e+00],\n",
       "         [ 2.3335e+00],\n",
       "         [ 2.2852e+00],\n",
       "         [ 4.7662e-01],\n",
       "         [ 1.8806e+00],\n",
       "         [ 5.9270e-01],\n",
       "         [ 2.9897e+00],\n",
       "         [-3.6969e-01],\n",
       "         [ 7.7684e-01],\n",
       "         [-5.7038e-01],\n",
       "         [ 1.1125e+00],\n",
       "         [-4.0287e+00],\n",
       "         [ 1.7890e+00],\n",
       "         [ 1.8043e+00],\n",
       "         [ 1.2846e+00],\n",
       "         [-1.5710e+00],\n",
       "         [ 8.4711e-01],\n",
       "         [-7.0784e-01],\n",
       "         [ 4.9895e-01],\n",
       "         [ 1.8778e+00],\n",
       "         [ 1.9235e+00],\n",
       "         [-1.5434e+00],\n",
       "         [ 1.0681e+00],\n",
       "         [-5.8955e+00],\n",
       "         [-3.2989e+00],\n",
       "         [ 1.1207e+00],\n",
       "         [ 1.2868e+00],\n",
       "         [-3.9817e-01],\n",
       "         [-6.3009e-01],\n",
       "         [-1.4428e+00],\n",
       "         [ 9.6103e-02],\n",
       "         [ 1.9018e+00],\n",
       "         [ 7.5519e-01],\n",
       "         [ 2.4955e+00],\n",
       "         [-1.0220e+00],\n",
       "         [-3.1800e+00],\n",
       "         [-1.9138e-01],\n",
       "         [-8.9966e-01],\n",
       "         [-5.4314e-01],\n",
       "         [-1.8321e+00],\n",
       "         [-1.5037e+00],\n",
       "         [-2.5452e+00],\n",
       "         [ 4.3391e+00],\n",
       "         [ 1.7047e+00],\n",
       "         [ 2.2422e+00],\n",
       "         [ 2.8773e+00],\n",
       "         [ 1.7072e+00],\n",
       "         [-1.2595e+00],\n",
       "         [ 2.0349e+00],\n",
       "         [ 2.9118e+00],\n",
       "         [ 4.6617e+00],\n",
       "         [ 1.2496e+00],\n",
       "         [ 4.7191e+00],\n",
       "         [ 6.8875e-01],\n",
       "         [ 1.4176e+00],\n",
       "         [-1.0001e+00],\n",
       "         [-2.5481e+00],\n",
       "         [ 2.4873e+00],\n",
       "         [-7.4330e-02],\n",
       "         [ 3.1317e+00],\n",
       "         [ 1.3966e+00],\n",
       "         [ 2.9934e-02],\n",
       "         [ 1.1011e+00],\n",
       "         [-1.6614e+00],\n",
       "         [ 2.9302e+00],\n",
       "         [-5.6139e-01],\n",
       "         [ 9.5471e-01],\n",
       "         [-1.3801e-01],\n",
       "         [ 1.2753e+00],\n",
       "         [-2.8323e+00],\n",
       "         [-2.1496e-02],\n",
       "         [ 1.5793e+00],\n",
       "         [ 2.4535e+00],\n",
       "         [ 3.6880e+00],\n",
       "         [-1.1660e+00],\n",
       "         [-3.5088e+00],\n",
       "         [ 1.4950e+00],\n",
       "         [ 2.3205e-02],\n",
       "         [-6.9659e-01],\n",
       "         [ 1.0580e+00],\n",
       "         [ 2.5549e+00],\n",
       "         [ 1.4970e+00],\n",
       "         [ 8.3772e-01],\n",
       "         [ 7.5859e-01],\n",
       "         [-1.3732e+00],\n",
       "         [ 1.3933e-01],\n",
       "         [-4.7852e-01],\n",
       "         [ 2.8737e+00],\n",
       "         [ 2.3998e+00],\n",
       "         [-1.5993e+00],\n",
       "         [-1.1303e+00],\n",
       "         [-8.5905e-01],\n",
       "         [-2.2129e+00],\n",
       "         [ 1.7260e+00],\n",
       "         [ 3.0332e+00],\n",
       "         [-3.7107e+00],\n",
       "         [ 7.0757e-01],\n",
       "         [-1.5311e-01],\n",
       "         [ 1.5049e+00],\n",
       "         [ 1.2171e+00],\n",
       "         [-3.8410e-01],\n",
       "         [ 1.8314e+00],\n",
       "         [-1.3360e-02],\n",
       "         [ 2.8441e+00],\n",
       "         [-1.7133e+00],\n",
       "         [ 1.0268e+00],\n",
       "         [-1.1809e+00],\n",
       "         [ 8.0700e-01],\n",
       "         [ 2.0303e+00],\n",
       "         [ 1.1999e+00],\n",
       "         [ 1.2877e+00],\n",
       "         [ 3.0709e+00],\n",
       "         [-2.3554e+00],\n",
       "         [ 1.9186e+00],\n",
       "         [ 2.7651e-01],\n",
       "         [ 3.9393e+00],\n",
       "         [ 4.0412e+00],\n",
       "         [ 2.5183e-01],\n",
       "         [-2.3268e+00],\n",
       "         [ 1.0712e+00],\n",
       "         [ 3.1705e+00],\n",
       "         [ 2.2294e+00],\n",
       "         [ 3.0268e+00],\n",
       "         [ 7.8925e-01],\n",
       "         [ 2.8267e+00],\n",
       "         [-1.9056e+00],\n",
       "         [ 2.8157e+00],\n",
       "         [-8.4583e-01],\n",
       "         [ 1.5551e-02],\n",
       "         [ 1.0777e+00],\n",
       "         [ 7.2464e-01],\n",
       "         [ 2.0362e+00],\n",
       "         [-2.7645e+00],\n",
       "         [-2.7717e+00],\n",
       "         [-1.2835e+00],\n",
       "         [ 1.7883e+00],\n",
       "         [ 3.6159e+00],\n",
       "         [ 2.4505e+00],\n",
       "         [ 2.5855e+00],\n",
       "         [-2.3340e-01],\n",
       "         [ 1.3438e+00],\n",
       "         [ 8.0920e-01],\n",
       "         [-7.9342e-02],\n",
       "         [ 1.3092e-01],\n",
       "         [ 1.0948e+00],\n",
       "         [ 1.3277e+00],\n",
       "         [ 2.0844e+00],\n",
       "         [-1.8718e+00],\n",
       "         [ 2.4393e+00],\n",
       "         [-2.0657e+00],\n",
       "         [ 4.5487e+00],\n",
       "         [ 1.4193e+00],\n",
       "         [-1.7314e-01],\n",
       "         [-1.5858e+00],\n",
       "         [ 2.1940e+00],\n",
       "         [ 1.6165e+00]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data_train.indices] # 返回训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0566,  0.6108],\n",
       "        [-0.0324, -1.0479],\n",
       "        [-0.2432, -0.3873],\n",
       "        ...,\n",
       "        [-1.7935, -1.0075],\n",
       "        [ 0.5288, -0.1329],\n",
       "        [ 0.2610, -0.0919]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data_train.indices][0] # 返回训练集的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0077e+00],\n",
       "        [ 1.6869e+00],\n",
       "        [-6.6230e-02],\n",
       "        [ 3.4079e+00],\n",
       "        [ 2.5114e+00],\n",
       "        [ 2.4704e+00],\n",
       "        [ 2.4293e+00],\n",
       "        [ 1.4161e+00],\n",
       "        [ 4.0741e+00],\n",
       "        [ 3.8438e+00],\n",
       "        [-1.9990e+00],\n",
       "        [ 2.3226e+00],\n",
       "        [-2.6314e-01],\n",
       "        [ 1.3193e-01],\n",
       "        [ 1.2485e+00],\n",
       "        [ 1.1407e+00],\n",
       "        [ 1.2932e+00],\n",
       "        [-2.2423e-01],\n",
       "        [-7.4660e-01],\n",
       "        [ 5.9922e-04],\n",
       "        [-1.2848e-01],\n",
       "        [ 1.1573e+00],\n",
       "        [-1.1735e+00],\n",
       "        [ 2.2792e+00],\n",
       "        [ 2.4111e+00],\n",
       "        [-1.4878e+00],\n",
       "        [-1.3235e+00],\n",
       "        [-2.6640e+00],\n",
       "        [ 6.9863e-01],\n",
       "        [-1.5456e+00],\n",
       "        [ 7.3890e-01],\n",
       "        [ 1.5608e-01],\n",
       "        [ 4.4044e+00],\n",
       "        [ 6.5633e-01],\n",
       "        [ 2.5553e+00],\n",
       "        [ 1.1644e+00],\n",
       "        [-4.0400e-01],\n",
       "        [ 3.4508e-02],\n",
       "        [ 3.4358e+00],\n",
       "        [ 1.6474e+00],\n",
       "        [ 1.2788e+00],\n",
       "        [-4.4499e-02],\n",
       "        [-8.0633e-01],\n",
       "        [ 1.6256e+00],\n",
       "        [ 6.9407e+00],\n",
       "        [ 9.0411e-01],\n",
       "        [ 4.3322e+00],\n",
       "        [ 3.4648e+00],\n",
       "        [ 4.0277e-01],\n",
       "        [ 4.2454e+00],\n",
       "        [ 5.3129e-02],\n",
       "        [ 4.7298e-01],\n",
       "        [ 3.5785e+00],\n",
       "        [ 2.2171e-01],\n",
       "        [-3.1615e-02],\n",
       "        [ 3.3872e+00],\n",
       "        [ 1.2096e+00],\n",
       "        [-1.4968e+00],\n",
       "        [ 1.6424e+00],\n",
       "        [ 3.1608e+00],\n",
       "        [ 1.4942e+00],\n",
       "        [-3.0629e+00],\n",
       "        [ 8.4887e+00],\n",
       "        [ 9.3990e-01],\n",
       "        [ 5.9216e-01],\n",
       "        [ 4.5548e-01],\n",
       "        [ 1.5157e+00],\n",
       "        [ 3.3853e+00],\n",
       "        [ 3.2574e+00],\n",
       "        [ 2.2729e+00],\n",
       "        [-4.5597e-01],\n",
       "        [-5.1551e-01],\n",
       "        [ 2.3458e+00],\n",
       "        [ 2.5706e+00],\n",
       "        [ 2.4336e-01],\n",
       "        [-5.4031e-01],\n",
       "        [ 3.2542e-01],\n",
       "        [-1.3734e+00],\n",
       "        [ 7.4853e-01],\n",
       "        [-4.1208e+00],\n",
       "        [-1.3196e+00],\n",
       "        [ 1.1917e+00],\n",
       "        [ 3.8248e+00],\n",
       "        [ 3.4568e+00],\n",
       "        [ 2.6842e+00],\n",
       "        [-5.7652e-01],\n",
       "        [-3.1880e-01],\n",
       "        [ 1.6234e+00],\n",
       "        [-7.8413e-01],\n",
       "        [-2.1648e+00],\n",
       "        [-1.1417e+00],\n",
       "        [ 1.7433e+00],\n",
       "        [ 3.3950e+00],\n",
       "        [ 1.6917e-01],\n",
       "        [-2.8134e+00],\n",
       "        [ 4.1692e-01],\n",
       "        [ 1.9967e+00],\n",
       "        [-1.0495e+00],\n",
       "        [-3.0442e-01],\n",
       "        [ 8.2525e-01],\n",
       "        [-1.8204e+00],\n",
       "        [ 1.6338e+00],\n",
       "        [ 2.6924e+00],\n",
       "        [ 5.4895e-01],\n",
       "        [ 2.4147e+00],\n",
       "        [ 1.2203e-01],\n",
       "        [-1.4078e+00],\n",
       "        [ 1.6300e+00],\n",
       "        [-2.1226e-01],\n",
       "        [ 1.1170e+00],\n",
       "        [-3.8838e+00],\n",
       "        [-2.5605e+00],\n",
       "        [ 1.0279e+00],\n",
       "        [ 4.0709e+00],\n",
       "        [ 8.5797e-01],\n",
       "        [-7.8190e-01],\n",
       "        [-9.0717e-01],\n",
       "        [ 8.8326e-01],\n",
       "        [ 3.6123e-01],\n",
       "        [-5.5309e+00],\n",
       "        [ 6.7663e-01],\n",
       "        [ 1.9394e+00],\n",
       "        [ 9.5632e-01],\n",
       "        [ 9.6378e-01],\n",
       "        [ 4.3220e-01],\n",
       "        [ 2.5204e+00],\n",
       "        [-6.2885e-02],\n",
       "        [-3.1349e-01],\n",
       "        [ 2.1921e+00],\n",
       "        [-8.2871e-01],\n",
       "        [ 8.6890e-01],\n",
       "        [-5.7794e-01],\n",
       "        [ 2.2633e+00],\n",
       "        [ 6.9073e+00],\n",
       "        [ 3.8688e-01],\n",
       "        [ 2.3816e+00],\n",
       "        [ 3.4423e+00],\n",
       "        [ 3.0327e+00],\n",
       "        [ 3.3939e+00],\n",
       "        [ 4.2385e+00],\n",
       "        [ 2.2081e+00],\n",
       "        [ 8.5789e-01],\n",
       "        [-1.1929e+00],\n",
       "        [ 2.7887e-01],\n",
       "        [ 3.7240e-01],\n",
       "        [-1.3552e+00],\n",
       "        [ 8.2157e-01],\n",
       "        [ 4.7876e+00],\n",
       "        [-3.4396e+00],\n",
       "        [-2.3389e-01],\n",
       "        [-4.2315e-01],\n",
       "        [ 3.5518e-01],\n",
       "        [ 3.1889e-01],\n",
       "        [ 3.2713e+00],\n",
       "        [-1.4741e+00],\n",
       "        [-2.0533e+00],\n",
       "        [-1.2774e+00],\n",
       "        [ 2.7336e+00],\n",
       "        [ 1.9926e+00],\n",
       "        [ 6.1340e+00],\n",
       "        [-2.1310e+00],\n",
       "        [-1.0053e+00],\n",
       "        [-2.8529e+00],\n",
       "        [ 1.7943e+00],\n",
       "        [ 1.9242e-01],\n",
       "        [-1.1637e-01],\n",
       "        [ 6.2861e-01],\n",
       "        [ 3.5545e+00],\n",
       "        [-6.8909e-01],\n",
       "        [ 2.1178e+00],\n",
       "        [-7.5717e-01],\n",
       "        [-2.7276e+00],\n",
       "        [ 1.6312e+00],\n",
       "        [ 7.8764e-01],\n",
       "        [ 4.7734e+00],\n",
       "        [ 4.7970e-01],\n",
       "        [ 4.8390e+00],\n",
       "        [-1.8485e-01],\n",
       "        [ 4.4562e+00],\n",
       "        [-6.2419e-01],\n",
       "        [ 8.8585e-01],\n",
       "        [-3.7029e+00],\n",
       "        [-1.2944e+00],\n",
       "        [ 5.7216e+00],\n",
       "        [ 5.6065e-01],\n",
       "        [ 5.0018e-02],\n",
       "        [ 1.4366e-01],\n",
       "        [-2.3206e+00],\n",
       "        [-1.4603e+00],\n",
       "        [-5.1734e+00],\n",
       "        [-3.9539e-01],\n",
       "        [-1.4849e+00],\n",
       "        [ 2.5661e+00],\n",
       "        [ 4.2380e+00],\n",
       "        [-1.8758e+00],\n",
       "        [ 3.0978e+00],\n",
       "        [ 7.7377e-01],\n",
       "        [ 1.9716e+00],\n",
       "        [-9.9379e-01],\n",
       "        [ 1.9403e+00],\n",
       "        [ 2.3158e+00],\n",
       "        [ 1.7284e-01],\n",
       "        [-4.9118e-01],\n",
       "        [-6.6277e-02],\n",
       "        [-8.5930e-01],\n",
       "        [ 3.0578e+00],\n",
       "        [-1.1961e+00],\n",
       "        [ 7.8309e-02],\n",
       "        [-1.2572e+00],\n",
       "        [-1.6609e+00],\n",
       "        [ 8.9468e-01],\n",
       "        [ 3.5173e+00],\n",
       "        [ 9.1596e-01],\n",
       "        [ 3.0868e+00],\n",
       "        [ 3.1231e+00],\n",
       "        [ 4.4137e+00],\n",
       "        [-4.4524e-01],\n",
       "        [-8.1427e-01],\n",
       "        [-1.9111e+00],\n",
       "        [ 3.4374e-02],\n",
       "        [ 2.9313e+00],\n",
       "        [ 1.2555e+00],\n",
       "        [ 1.7973e+00],\n",
       "        [-3.1967e-01],\n",
       "        [ 1.2251e+00],\n",
       "        [ 2.7613e+00],\n",
       "        [ 9.0878e-01],\n",
       "        [ 4.2557e+00],\n",
       "        [-3.4801e+00],\n",
       "        [-9.3447e-01],\n",
       "        [-2.1655e+00],\n",
       "        [-2.9859e+00],\n",
       "        [ 2.3526e+00],\n",
       "        [-1.9583e+00],\n",
       "        [ 1.6130e+00],\n",
       "        [ 4.4866e-01],\n",
       "        [-1.1534e+00],\n",
       "        [ 2.7258e+00],\n",
       "        [ 2.7663e+00],\n",
       "        [-4.2485e+00],\n",
       "        [-1.1087e+00],\n",
       "        [-2.4512e-01],\n",
       "        [ 1.8514e+00],\n",
       "        [-9.2312e-02],\n",
       "        [-2.4665e+00],\n",
       "        [-1.9434e+00],\n",
       "        [ 3.4155e+00],\n",
       "        [-7.5120e-02],\n",
       "        [ 2.5360e+00],\n",
       "        [-2.3473e+00],\n",
       "        [-8.5017e-01],\n",
       "        [ 7.2002e-01],\n",
       "        [ 1.5546e+00],\n",
       "        [-1.8711e-01],\n",
       "        [ 2.3886e+00],\n",
       "        [ 3.0652e-01],\n",
       "        [ 1.0687e+00],\n",
       "        [ 1.9056e+00],\n",
       "        [ 4.4225e+00],\n",
       "        [ 5.1038e-01],\n",
       "        [ 9.5112e-01],\n",
       "        [ 8.4017e-01],\n",
       "        [ 3.7159e-01],\n",
       "        [ 4.5087e-01],\n",
       "        [ 4.9309e-01],\n",
       "        [ 5.7908e+00],\n",
       "        [-1.9308e+00],\n",
       "        [-3.2576e+00],\n",
       "        [-1.8314e+00],\n",
       "        [ 2.1173e+00],\n",
       "        [ 2.5476e-01],\n",
       "        [ 2.3033e+00],\n",
       "        [ 1.4304e+00],\n",
       "        [ 5.1168e+00],\n",
       "        [ 1.7836e+00],\n",
       "        [-2.2061e+00],\n",
       "        [ 6.1516e+00],\n",
       "        [ 2.5655e+00],\n",
       "        [ 1.0627e+00],\n",
       "        [ 3.6949e+00],\n",
       "        [-2.3982e+00],\n",
       "        [-2.5665e-01],\n",
       "        [ 6.5455e+00],\n",
       "        [ 4.2039e+00],\n",
       "        [ 1.0460e+00],\n",
       "        [ 2.9082e-01],\n",
       "        [-2.1287e+00],\n",
       "        [-4.5076e-01],\n",
       "        [-8.6392e-01],\n",
       "        [ 1.4310e+00],\n",
       "        [ 2.9898e+00],\n",
       "        [ 2.5826e+00],\n",
       "        [-1.5230e+00],\n",
       "        [ 4.8341e-01],\n",
       "        [-1.2284e+00],\n",
       "        [-8.1724e-02],\n",
       "        [-7.3333e-01],\n",
       "        [-1.3407e+00],\n",
       "        [-2.2389e+00],\n",
       "        [-6.9455e-01]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data_test.indices][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.5879e-05, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算训练集MSE\n",
    "F.mse_loss(LR_model(data[data_train.indices][0]), data[data_train.indices][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.2361e-05, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算测试集MSE\n",
    "F.mse_loss(LR_model(data[data_test.indices][0]), data[data_test.indices][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实用数据补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个针对手动创建数据的数据类\n",
    "class GenData(Dataset):\n",
    "    def __init__(self,features,lables): # 创建该类时需要输入的数据集\n",
    "        self.features = features\n",
    "        self.labels  = labels\n",
    "        self.lens = len(features)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.features[index,:],self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.lens\n",
    "    \n",
    "def split_loader(features,labels,batch_size=10,rate=0.7):\n",
    "    \"\"\"数据封装、切分和加载数据\n",
    "    \n",
    "    param features: 输入的特征\n",
    "    param labele: 数据集标签张量\n",
    "    param batch_size: 数据加载时的每一个小批数据量\n",
    "    param rate: 训练集数据占比\n",
    "    return : 加载好的训练集和测试集\n",
    "    \n",
    "    \"\"\"\n",
    "    data = GenData(features,labels)\n",
    "    num_train = int(data.lens * 0.7)\n",
    "    num_test = data.lens - num_train\n",
    "    \n",
    "    data_train,data_test = random_split(data,[num_train,num_test])\n",
    "    train_loader = DataLoader(data_train,batch_size=batch_size,shuffle=True)\n",
    "    test_loader = DataLoader(data_test,batch_size=batch_size,shuffle=False)\n",
    "    \n",
    "    return (train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net,criterion,optimizer,batchData,epochs=3,cla=False):\n",
    "    \"\"\"模型训练函数\n",
    "    param net: 待训练的模型\n",
    "    param citerion: 损失函数\n",
    "    param optimizer: 优化算法\n",
    "    param batchData: 训练数据集\n",
    "    param cla: 是否是分类问题\n",
    "    param epochs: 遍历数据次数\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for X,y in batchData:\n",
    "            if cla == True:\n",
    "                y = y.flatten().long() # 如果是分类问题，要对y进行整数转化\n",
    "            yhat = net.forward(X)\n",
    "            loss = criterion(yhat,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_cal(data_loader,net):\n",
    "    \"\"\"mse计算函数\n",
    "    \n",
    "    param data_Loader:加载好的数据\n",
    "    param net:模型\n",
    "    return :根据输入的数据，输出其MSE计算的结果\n",
    "    \n",
    "    \"\"\"\n",
    "    data = data_loader.dataset # 还原 Dataset类\n",
    "    x = data[:][0] # 还原数据的特征\n",
    "    y = data[:][1] # 还原数据的标签\n",
    "    yhat = net(x)\n",
    "    \n",
    "    return F.mse_loss(yhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1511, -1.5656],\n",
       "        [-1.3589,  0.3561],\n",
       "        [ 0.3944, -1.5511],\n",
       "        ...,\n",
       "        [ 1.7895,  1.0660],\n",
       "        [-0.8417,  1.8088],\n",
       "        [-0.4877,  0.3996]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbe3e474210>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "\n",
    "# 实例化模型\n",
    "LR_model = LR()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(LR_model.parameters(),lr=0.03)\n",
    "\n",
    "fit(net = LR_model,\n",
    "    criterion = criterion,\n",
    "    optimizer = optimizer,\n",
    "    batchData = train_loader,\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_cal(train_loader,LR_model) # 计算训练误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.4898e-05, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_cal(test_loader,LR_model) # 计算测试误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准确率计算函数\n",
    "def accuracy_cal(data_loader,net):\n",
    "    \"\"\"准确率\n",
    "    param data_loader: 加载好的数据\n",
    "    param net: 数据\n",
    "    return : 根据输入的数据，输出其准确率计算结果\n",
    "    \n",
    "    \"\"\"\n",
    "    data = data_loader.dataset # 还原 Dataset 类\n",
    "    X = data[:][0] # 还原数据的特征\n",
    "    y = data[:][1] # 还原数据的标签\n",
    "    zhat = net(X) # 默认是分类问题，并且输出结果是未经softmax转化的结果\n",
    "    soft_z = F.softmax(zhat,1) # 进行softmax转化\n",
    "    acc_bool = torch.argmax(soft_z,1).flatten() == y.flatten() # 每条数据最大值结果所属的类别与标签是否一致 1 列\n",
    "    acc = torch.mean(acc_bool.float())\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(9).reshape(3,3).float()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(t,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbe3e474210>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "\n",
    "features,labels = tensorGenCla()\n",
    "\n",
    "train_loader,test_loader = split_loader(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmaxR(nn.Module):\n",
    "    def __init__(self,in_features=2,out_features=3,bias=False):\n",
    "        super(softmaxR,self).__init__()\n",
    "        self.linear = nn.Linear(in_features,out_features)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 实例化模型\n",
    "softmax_model = softmaxR()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(softmax_model.parameters(),lr=lr)\n",
    "\n",
    "fit(net = softmax_model,\n",
    "   criterion = criterion,\n",
    "   optimizer = optimizer,\n",
    "   batchData = train_loader,\n",
    "   epochs= num_epochs,\n",
    "   cla = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8790)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cal(train_loader,softmax_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8711)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cal(test_loader,softmax_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
