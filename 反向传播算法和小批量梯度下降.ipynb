{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 梯度下降\n",
    "# 例一\n",
    "x = torch.tensor(1,requires_grad=True,dtype=torch.float32)\n",
    "y = x**2\n",
    "torch.autograd.grad(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例二\n",
    "x = torch.tensor(1,requires_grad=True,dtype=torch.float32)\n",
    "z = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(2,requires_grad=True,dtype=torch.float32) #真实标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -(y*torch.log(sigma) + (1-y)*torch.log(1-sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.0000),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(loss,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反向传播\n",
    "\n",
    "# 3分类，500个样本，20个特征，共3层\n",
    "# 第一层13个神经元，第二层8个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定数据\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络的架构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,in_features=40,out_features=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features,13,bias=False)\n",
    "        self.linear2 = nn.Linear(13,8,bias=False)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        sigma1 = torch.relu(self.linear1(x)) # 激活函数（层的线性结果）\n",
    "\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        \"\"\"\n",
    "        三分类的损失函数无论是使用logsoftmax+NLLLoss还是交叉熵,都不需要计算sigmoid,在层的最后要么写logsoftmax，要么不写\n",
    "        二分类考虑使用BCE，BCEWithLogitsLoss\n",
    "        \"\"\"\n",
    "        zhat = self.output(sigma2)\n",
    "        \n",
    "        return zhat               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = X.shape[1]\n",
    "output_ = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "net = Net(in_features=input_,out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhat = net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "from torch.nn import CrossEntropyLoss as CEL\n",
    "criterion = CEL()\n",
    "loss = criterion(zhat,y.long()) # 交叉熵只接受整型的y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1559, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.linear1.weight.grad #还没有梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0294e-04, -7.4870e-05, -3.6707e-04, -3.8675e-05, -1.3070e-04,\n",
       "         -5.8467e-05, -3.3313e-04, -2.5863e-04, -9.4272e-05, -4.2617e-05,\n",
       "         -7.9181e-05, -1.5179e-04, -9.2079e-05, -3.2513e-04, -1.0894e-04,\n",
       "         -6.5035e-05, -1.3006e-04, -4.4115e-06, -9.6740e-05, -8.5472e-05],\n",
       "        [ 1.0099e-02, -9.9187e-04,  1.2005e-02,  1.0411e-03,  5.1961e-03,\n",
       "          3.5567e-03,  6.0618e-03,  3.9976e-03,  1.4981e-02,  9.0948e-03,\n",
       "          6.0929e-03,  7.5188e-03,  1.3888e-02,  1.1927e-03,  8.9806e-03,\n",
       "          9.8215e-03,  1.7637e-02,  1.0377e-02,  1.6778e-03,  7.8359e-04],\n",
       "        [-1.0467e-02,  7.9738e-03,  3.0350e-03,  7.4985e-03,  4.3230e-03,\n",
       "          9.8743e-04,  9.2578e-03,  6.3660e-03, -5.8071e-03,  1.1588e-03,\n",
       "         -2.6623e-03,  6.3559e-03, -2.9338e-03, -4.4924e-03, -5.0406e-03,\n",
       "          8.4390e-03, -1.0344e-02, -8.5044e-03,  2.1374e-03, -1.2447e-03],\n",
       "        [-1.3464e-02, -1.0530e-02, -8.3316e-03, -1.5648e-02, -1.2376e-02,\n",
       "         -1.6419e-02, -9.7809e-03, -1.6176e-02, -7.5129e-03, -1.6220e-02,\n",
       "         -1.0425e-02, -7.7203e-03, -2.6543e-03, -1.4025e-02, -9.4273e-03,\n",
       "         -1.4208e-02, -9.8492e-03, -1.2527e-02, -1.9432e-02, -1.1801e-02],\n",
       "        [-2.4001e-02, -2.2049e-02, -1.9075e-02, -2.4805e-02, -1.4982e-02,\n",
       "         -1.4487e-02, -1.7842e-02, -2.5486e-02, -1.6000e-02, -3.2270e-02,\n",
       "         -6.3227e-03, -2.9843e-02, -4.5610e-03, -1.3760e-02, -1.5680e-02,\n",
       "         -2.4157e-02, -2.1648e-02, -1.4690e-02, -2.2686e-02, -2.0136e-02],\n",
       "        [-4.9099e-04,  1.2938e-03, -3.2794e-04, -5.8756e-04, -1.0274e-04,\n",
       "          1.4246e-03, -3.4932e-04,  9.8298e-04, -2.5764e-04, -1.4621e-04,\n",
       "         -4.4740e-04, -2.5354e-04,  1.9017e-04, -8.4186e-04,  2.5199e-04,\n",
       "          2.6533e-04,  2.6516e-04,  1.0733e-03,  1.0434e-03, -2.7481e-04],\n",
       "        [ 1.8667e-02,  2.0105e-02,  1.4331e-02,  1.7148e-02,  7.1022e-03,\n",
       "          2.9474e-02,  1.9639e-02,  1.6606e-02, -3.9072e-03,  5.3112e-02,\n",
       "          2.5341e-03,  3.9633e-02,  6.0932e-03,  2.2678e-02,  3.3614e-03,\n",
       "          3.0149e-02,  1.6826e-02,  1.6251e-02,  3.4115e-02,  2.9516e-02],\n",
       "        [ 2.5575e-02,  5.2925e-03,  6.6924e-03,  4.6901e-03,  8.3948e-03,\n",
       "          5.2274e-03,  3.1384e-03,  6.9073e-03,  2.7986e-02,  4.0137e-03,\n",
       "          1.0056e-02,  9.9030e-03,  1.4389e-02,  1.5045e-02,  1.7513e-02,\n",
       "          5.1190e-03,  2.0432e-02,  1.7921e-02,  1.2467e-02,  1.0877e-03],\n",
       "        [-2.6368e-02, -2.5858e-02, -2.9701e-02, -2.3503e-02, -2.4305e-02,\n",
       "         -3.3645e-02, -1.9366e-02, -2.3217e-02, -1.2061e-02, -3.7455e-02,\n",
       "         -1.4216e-02, -3.7164e-02, -1.6988e-02, -2.9700e-02, -2.0395e-02,\n",
       "         -3.6110e-02, -2.7453e-02, -1.9892e-02, -3.7484e-02, -4.0446e-02],\n",
       "        [ 3.0670e-03,  2.3949e-03,  5.5598e-03, -5.5753e-03, -5.0398e-03,\n",
       "         -6.5433e-03,  7.7753e-04, -7.7903e-03, -2.6769e-03, -5.9714e-04,\n",
       "         -1.7679e-03, -2.9360e-03,  7.9957e-04, -1.0231e-03, -1.6204e-03,\n",
       "          1.7842e-03,  8.9686e-04, -2.2975e-03,  2.1827e-03,  1.3285e-03],\n",
       "        [ 5.1343e-03,  1.7690e-03,  2.3953e-03,  3.4648e-03,  1.6590e-03,\n",
       "          5.5399e-04,  5.7126e-05,  9.1988e-04,  1.9024e-03,  3.2499e-03,\n",
       "          2.7058e-03,  1.0736e-03,  1.9884e-03,  2.1006e-03,  1.6670e-03,\n",
       "          1.1112e-03,  2.9293e-03,  4.1532e-03,  2.9811e-03,  2.6034e-03],\n",
       "        [-1.0980e-02, -1.1791e-02, -2.0945e-03, -5.3406e-03, -8.9154e-03,\n",
       "         -1.1582e-02, -5.7907e-03, -1.3181e-02, -1.8497e-02, -1.3750e-02,\n",
       "         -5.2399e-03, -7.5829e-03, -1.1019e-02, -1.4631e-02, -9.4829e-03,\n",
       "         -7.1365e-03, -1.3495e-02, -1.0724e-02, -1.0035e-02, -4.0535e-03],\n",
       "        [ 2.5406e-04,  3.8109e-04,  6.1133e-05,  5.1588e-04,  1.0562e-03,\n",
       "          9.5466e-04,  6.7450e-04,  1.0621e-03,  1.1541e-04,  1.8141e-03,\n",
       "          5.5162e-04,  6.6329e-04,  2.4456e-04,  1.9338e-04,  1.0474e-03,\n",
       "          1.9811e-04,  4.7523e-04,  1.6118e-03,  5.2851e-04,  2.4157e-04]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 20])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() #除非再次执行正向传播，否则反向传播只能执行一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 20])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backwrd是靠requires_grad = True来求解梯度的\n",
    "# 正常梯度下降和反向传播过程中，X和y不需要计算导数，不设置requires_grad,默认其为False,以节约计算资源\n",
    "# 如果自己设置w，则一定要设置requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w(t+1) = w(t) - 步长*grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10 # 学习率，一般为0.001，0.01，0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = net.linear1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w -= lr*dw # 一次梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1426, -0.1331,  0.2201, -0.1769, -0.0656, -0.1529,  0.1791,  0.0891,\n",
       "         -0.1096, -0.1721, -0.1279, -0.0401, -0.1123,  0.1694, -0.0919, -0.1450,\n",
       "         -0.0664, -0.2183, -0.1067, -0.1203],\n",
       "        [-0.1538,  0.2017, -0.2160, -0.1511, -0.0119, -0.1663, -0.2271, -0.1228,\n",
       "         -0.4163, -0.1573,  0.0597, -0.1199, -0.1427, -0.2181, -0.3555, -0.2262,\n",
       "         -0.3525, -0.0680, -0.2302,  0.0776],\n",
       "        [ 0.0174, -0.1234,  0.0871, -0.1191, -0.0151,  0.1224,  0.0361, -0.2676,\n",
       "          0.1894,  0.1609,  0.1804, -0.3296, -0.0964, -0.1291,  0.1998,  0.0525,\n",
       "         -0.0097,  0.3489, -0.2520, -0.0024],\n",
       "        [ 0.4507,  0.1754,  0.1914,  0.4759,  0.0600,  0.3850,  0.0865,  0.5287,\n",
       "         -0.0435,  0.3413,  0.3482,  0.0230, -0.0789,  0.3571,  0.0130,  0.4151,\n",
       "          0.2242,  0.0304,  0.4655,  0.0487],\n",
       "        [ 0.5074,  0.5780,  0.3428,  0.5796,  0.2840,  0.1219,  0.1426,  0.6944,\n",
       "          0.4039,  0.7053, -0.0789,  0.5690,  0.1387,  0.0774,  0.1352,  0.5968,\n",
       "          0.5740,  0.1559,  0.5708,  0.3686],\n",
       "        [ 0.0482, -0.1986, -0.0958, -0.1146, -0.1168, -0.1631, -0.1691,  0.0169,\n",
       "         -0.1732, -0.1618,  0.2173,  0.1891, -0.0925, -0.0585,  0.1737, -0.0626,\n",
       "         -0.0298, -0.0333, -0.2028,  0.2036],\n",
       "        [-0.3954, -0.1836, -0.1025, -0.2458, -0.1471, -0.5919, -0.3876, -0.5495,\n",
       "          0.0248, -1.1657, -0.0640, -0.7653, -0.2971, -0.2836,  0.1154, -0.4639,\n",
       "         -0.2361, -0.2896, -0.8434, -0.5003],\n",
       "        [-0.4323,  0.1103, -0.3447,  0.1003,  0.0077, -0.0631,  0.0117, -0.1114,\n",
       "         -0.5776, -0.0352, -0.0716, -0.1726, -0.3081, -0.3083, -0.5225, -0.2094,\n",
       "         -0.2266, -0.3452, -0.2259, -0.2174],\n",
       "        [ 0.6907,  0.5252,  0.5641,  0.2512,  0.6208,  0.6440,  0.1997,  0.4733,\n",
       "          0.4506,  0.8400,  0.2013,  0.7342,  0.4402,  0.5771,  0.2705,  0.8902,\n",
       "          0.3556,  0.3630,  0.8502,  0.8312],\n",
       "        [ 0.0848,  0.0962, -0.1343,  0.1935,  0.1068,  0.1985,  0.1370,  0.3232,\n",
       "         -0.1154,  0.1276, -0.1500,  0.0820, -0.1775,  0.1228, -0.1407, -0.2247,\n",
       "         -0.2208,  0.0247, -0.0655, -0.0645],\n",
       "        [ 0.0911,  0.0185, -0.1969,  0.0978, -0.1997,  0.0513, -0.0427, -0.2240,\n",
       "         -0.1745, -0.2710, -0.2444, -0.1104, -0.1178,  0.1212, -0.1651,  0.0364,\n",
       "          0.1526,  0.0840, -0.1191, -0.2618],\n",
       "        [ 0.1940,  0.2250,  0.0088,  0.1439,  0.0702,  0.4381,  0.2398,  0.0484,\n",
       "          0.4917,  0.1318,  0.2181,  0.1986,  0.3049,  0.4979,  0.0713,  0.3356,\n",
       "          0.2415,  0.2216, -0.0098,  0.1891],\n",
       "        [-0.1277, -0.0759, -0.2205, -0.1597,  0.1711, -0.0820, -0.0899,  0.1983,\n",
       "         -0.0481, -0.0265, -0.0140, -0.1085, -0.0847, -0.1910,  0.1573, -0.1795,\n",
       "         -0.1128, -0.0519, -0.1851,  0.0156]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动量法momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(t) = gamma * v(t-1) - lr * dw\n",
    "# w(t+1) = w(t) + v(t) 上一步和这一步方向的向量和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = net.linear1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 1,走第一步，首次迭代，初始化v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.zeros(dw.shape[0],dw.shape[1]) # 为了v和dw梯度可以相减，结构维度应该一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一次迭代 \n",
    "v = gamma * v - lr * dw\n",
    "w += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4317e-01, -1.3296e-01,  2.2081e-01, -1.7678e-01, -6.5368e-02,\n",
       "         -1.5282e-01,  1.7972e-01,  8.9526e-02, -1.0947e-01, -1.7201e-01,\n",
       "         -1.2774e-01, -3.9827e-02, -1.1212e-01,  1.7004e-01, -9.1706e-02,\n",
       "         -1.4487e-01, -6.6146e-02, -2.1827e-01, -1.0648e-01, -1.2013e-01],\n",
       "        [-1.7212e-01,  2.0349e-01, -2.3769e-01, -1.5302e-01, -2.1269e-02,\n",
       "         -1.7277e-01, -2.3804e-01, -1.3004e-01, -4.4342e-01, -1.7377e-01,\n",
       "          4.8634e-02, -1.3348e-01, -1.6785e-01, -2.2027e-01, -3.7178e-01,\n",
       "         -2.4396e-01, -3.8446e-01, -8.6759e-02, -2.3325e-01,  7.6203e-02],\n",
       "        [ 3.6367e-02, -1.3784e-01,  8.1585e-02, -1.3270e-01, -2.2892e-02,\n",
       "          1.2063e-01,  1.9306e-02, -2.7916e-01,  1.9991e-01,  1.5882e-01,\n",
       "          1.8522e-01, -3.4115e-01, -9.1099e-02, -1.2101e-01,  2.0892e-01,\n",
       "          3.7182e-02,  9.0076e-03,  3.6428e-01, -2.5583e-01, -1.2852e-04],\n",
       "        [ 4.7509e-01,  1.9449e-01,  2.0651e-01,  5.0426e-01,  8.2361e-02,\n",
       "          4.1469e-01,  1.0421e-01,  5.5802e-01, -2.9929e-02,  3.7066e-01,\n",
       "          3.6703e-01,  3.7006e-02, -7.4116e-02,  3.8245e-01,  3.0025e-02,\n",
       "          4.4084e-01,  2.4199e-01,  5.3112e-02,  5.0069e-01,  7.0065e-02],\n",
       "        [ 5.5087e-01,  6.1788e-01,  3.7734e-01,  6.2445e-01,  3.1113e-01,\n",
       "          1.4815e-01,  1.7486e-01,  7.4048e-01,  4.3286e-01,  7.6375e-01,\n",
       "         -6.7483e-02,  6.2303e-01,  1.4692e-01,  1.0228e-01,  1.6355e-01,\n",
       "          6.4049e-01,  6.1314e-01,  1.8244e-01,  6.1182e-01,  4.0505e-01],\n",
       "        [ 4.9096e-02, -2.0090e-01, -9.5202e-02, -1.1353e-01, -1.1659e-01,\n",
       "         -1.6570e-01, -1.6848e-01,  1.5104e-02, -1.7272e-01, -1.6152e-01,\n",
       "          2.1810e-01,  1.8953e-01, -9.2870e-02, -5.7017e-02,  1.7327e-01,\n",
       "         -6.3046e-02, -3.0305e-02, -3.5231e-02, -2.0471e-01,  2.0412e-01],\n",
       "        [-4.2914e-01, -2.2002e-01, -1.2846e-01, -2.7682e-01, -1.5996e-01,\n",
       "         -6.4529e-01, -4.2319e-01, -5.7951e-01,  3.1841e-02, -1.2618e+00,\n",
       "         -6.8571e-02, -8.3704e-01, -3.0812e-01, -3.2465e-01,  1.0928e-01,\n",
       "         -5.1848e-01, -2.6656e-01, -3.1905e-01, -9.0517e-01, -5.5369e-01],\n",
       "        [-4.7856e-01,  1.0071e-01, -3.5682e-01,  9.1781e-02, -7.4957e-03,\n",
       "         -7.2538e-02,  6.0338e-03, -1.2391e-01, -6.2825e-01, -4.2499e-02,\n",
       "         -8.9846e-02, -1.9050e-01, -3.3413e-01, -3.3552e-01, -5.5417e-01,\n",
       "         -2.1869e-01, -2.6359e-01, -3.7768e-01, -2.4844e-01, -2.1939e-01],\n",
       "        [ 7.3846e-01,  5.7198e-01,  6.1789e-01,  2.9376e-01,  6.6479e-01,\n",
       "          7.0490e-01,  2.3479e-01,  5.1527e-01,  4.7244e-01,  9.0782e-01,\n",
       "          2.2707e-01,  8.0146e-01,  4.7096e-01,  6.3086e-01,  3.0745e-01,\n",
       "          9.5557e-01,  4.0534e-01,  3.9903e-01,  9.1807e-01,  9.0440e-01],\n",
       "        [ 7.9222e-02,  9.1908e-02, -1.4435e-01,  2.0354e-01,  1.1590e-01,\n",
       "          2.1038e-01,  1.3558e-01,  3.3733e-01, -1.1058e-01,  1.2873e-01,\n",
       "         -1.4682e-01,  8.7349e-02, -1.7891e-01,  1.2461e-01, -1.3779e-01,\n",
       "         -2.2797e-01, -2.2242e-01,  2.8898e-02, -6.9403e-02, -6.6895e-02],\n",
       "        [ 8.1773e-02,  1.5340e-02, -2.0124e-01,  9.1520e-02, -2.0270e-01,\n",
       "          5.0281e-02, -4.2820e-02, -2.2571e-01, -1.7798e-01, -2.7688e-01,\n",
       "         -2.4933e-01, -1.1236e-01, -1.2143e-01,  1.1742e-01, -1.6810e-01,\n",
       "          3.4403e-02,  1.4728e-01,  7.6492e-02, -1.2451e-01, -2.6651e-01],\n",
       "        [ 2.1383e-01,  2.4635e-01,  1.2631e-02,  1.5355e-01,  8.6350e-02,\n",
       "          4.5902e-01,  2.5025e-01,  7.2239e-02,  5.2513e-01,  1.5666e-01,\n",
       "          2.2763e-01,  2.1231e-01,  3.2488e-01,  5.2439e-01,  8.8492e-02,\n",
       "          3.4851e-01,  2.6594e-01,  2.4104e-01,  8.3123e-03,  1.9645e-01],\n",
       "        [-1.2812e-01, -7.6636e-02, -2.2063e-01, -1.6065e-01,  1.6922e-01,\n",
       "         -8.3743e-02, -9.1087e-02,  1.9639e-01, -4.8356e-02, -2.9764e-02,\n",
       "         -1.4971e-02, -1.0971e-01, -8.5109e-02, -1.9130e-01,  1.5544e-01,\n",
       "         -1.7984e-01, -1.1364e-01, -5.4850e-02, -1.8602e-01,  1.5139e-02]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim 优化算法模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# 导入库\n",
    "# 确定数据、超参数（lr，gamma）\n",
    "# 定义神经网络的架构 Model,类Model需要输入的参数\n",
    "# 实例化神经网络的类 - 让神经网络准备好正向传播\n",
    "# 定义损失函数\n",
    "# 定义优化算法\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "# 确定数据\n",
    "\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)\n",
    "\n",
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# 定义神经网络的架构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,in_features=40,out_features=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features,13,bias=False)\n",
    "        self.linear2 = nn.Linear(13,8,bias=False)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        sigma1 = torch.relu(self.linear1(x)) # 激活函数（层的线性结果）\n",
    "\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        \"\"\"\n",
    "        三分类的损失函数无论是使用logsoftmax+NLLLoss还是交叉熵,都不需要计算sigmoid,在层的最后要么写logsoftmax，要么不写\n",
    "        二分类考虑使用BCE，BCEWithLogitsLoss\n",
    "        \"\"\"\n",
    "        zhat = self.output(sigma2)\n",
    "        \n",
    "        return zhat \n",
    "\n",
    "input_ = X.shape[1] # 特征数目\n",
    "output_ = len(y.unique()) # 分类数目\n",
    "\n",
    "# 实例化神经网络类\n",
    "torch.manual_seed(420)\n",
    "net = Net(in_features=input_,out_features=output_)\n",
    "\n",
    "# 定义损失函数\n",
    "from torch.nn import CrossEntropyLoss as CEL\n",
    "criterion = CEL()\n",
    "\n",
    "# 定义优化算法,小批量梯度下降\n",
    "# net.parameters()一次性导出现有神经网络架构下全部的权重和截距，net.linear1.weight只有一层的\n",
    "opt = optim.SGD( net.parameters()# 需要进行迭代的权重\n",
    "                ,lr = lr\n",
    "                ,momentum = gamma\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n梯度下降流程\\n向前传播\\n本轮向前传播的损失函数值\\n反向传播 -》 得到了梯度\\n更新权重（和动量）\\n清空梯度：清楚上一次迭代的坐标计算的梯度\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# 梯度下降流程\n",
    "# 向前传播\n",
    "# 本轮向前传播的损失函数值\n",
    "# 反向传播 -》 得到了梯度\n",
    "# 更新权重（和动量）\n",
    "# 清空梯度：清楚上一次迭代的坐标计算的梯度\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0606, grad_fn=<NllLossBackward>)\n",
      "tensor([ 0.1430, -0.1330,  0.2206, -0.1768, -0.0655, -0.1529,  0.1795,  0.0893,\n",
      "        -0.1095, -0.1720])\n"
     ]
    }
   ],
   "source": [
    "zhat = net.forward(X) # zhat 最后一个线性层的输出结果，向前传播\n",
    "loss = criterion(zhat,y.reshape(500).long()) # 计算损失函数\n",
    "loss.backward()\n",
    "opt.step() # step是步子，走一步，更新权重w，更新动量v\n",
    "opt.zero_grad()\n",
    "\n",
    "print(loss)\n",
    "print(net.linear1.weight.data[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传统梯度下降GD\n",
    "# 小批量梯度下降 mini-batch SGD 每次随机同样数量的数据\n",
    "# 优化算法的目标：全局最优\n",
    "# 梯度下降每次数据完整，X相同，方向与w有关，小批量梯度下降方向与X和w有关，更可能跳出局部最小\n",
    "# 小批量梯度下降由于方向不太明确，迭代次数可能比梯度下降更多，也可能更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 全体数据一共被学习了多少次\n",
    "# 每次迭代都只使用了一部分数据，1个epoch需要多次迭代，全体数据都使用了一次\n",
    "# 一个epoch需要的迭代次数n：n = m个样本 / NB 小批量batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 60 #让神经网络学习60次数据\n",
    "batch = 10 # 每次将全部数据X划分为10个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度下降迭代\n",
    "for epoch in range(epoch):\n",
    "    for batch in range(batch):\n",
    "        zhat = net.forward(X) # zhat 最后一个线性层的输出结果，向前传播\n",
    "        loss = criterion(zhat,y.reshape(500).long()) # 计算损失函数\n",
    "        loss.backward()\n",
    "        opt.step() # step是步子，走一步，更新权重w，更新动量v\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理 torch.utils\n",
    "# TensorDataset合并与DataLoader分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(500,2,3) # 三维数据-二维表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(500,3,4,5) # 四维数据-图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randn(500,1) # 二维数据 - 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并abc，被合并数据第一维度上的值相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0555,  0.0347, -0.0640],\n",
      "        [-0.6151,  0.5850, -1.3424]]), tensor([[[ 1.4229,  0.3269, -0.7064,  0.4886, -0.4457],\n",
      "         [-0.1819,  1.3381, -0.0515,  0.9612,  0.6173],\n",
      "         [ 2.1468,  0.0329, -1.3354, -0.2216, -1.2585],\n",
      "         [-0.0606, -0.7752,  1.5580,  0.8701,  2.0751]],\n",
      "\n",
      "        [[-0.4195,  0.3641,  1.1461,  1.3315,  0.6182],\n",
      "         [ 0.4945,  0.4110,  0.4114, -1.9308, -0.2237],\n",
      "         [ 0.4374,  0.4338,  0.5920,  0.7556, -0.4258],\n",
      "         [ 1.5789, -0.1794, -0.5889,  1.8905, -0.7718]],\n",
      "\n",
      "        [[-0.7557, -1.2767,  1.0856,  0.7704,  2.3633],\n",
      "         [ 0.0490, -0.9121, -0.0489, -1.2371, -1.2507],\n",
      "         [-2.2677, -0.1536, -0.2799, -0.9272,  1.4546],\n",
      "         [-0.8360, -0.3864, -0.9757, -0.5694,  0.2240]]]), tensor([-0.1178]))\n"
     ]
    }
   ],
   "source": [
    "for x in TensorDataset(a,b,c): # generator\n",
    "    print(x) # 元组\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 1.4229,  0.3269, -0.7064,  0.4886, -0.4457],\n",
      "          [-0.1819,  1.3381, -0.0515,  0.9612,  0.6173],\n",
      "          [ 2.1468,  0.0329, -1.3354, -0.2216, -1.2585],\n",
      "          [-0.0606, -0.7752,  1.5580,  0.8701,  2.0751]],\n",
      "\n",
      "         [[-0.4195,  0.3641,  1.1461,  1.3315,  0.6182],\n",
      "          [ 0.4945,  0.4110,  0.4114, -1.9308, -0.2237],\n",
      "          [ 0.4374,  0.4338,  0.5920,  0.7556, -0.4258],\n",
      "          [ 1.5789, -0.1794, -0.5889,  1.8905, -0.7718]],\n",
      "\n",
      "         [[-0.7557, -1.2767,  1.0856,  0.7704,  2.3633],\n",
      "          [ 0.0490, -0.9121, -0.0489, -1.2371, -1.2507],\n",
      "          [-2.2677, -0.1536, -0.2799, -0.9272,  1.4546],\n",
      "          [-0.8360, -0.3864, -0.9757, -0.5694,  0.2240]]]]), tensor([[-0.1178]])]\n"
     ]
    }
   ],
   "source": [
    "for x in DataLoader(data):\n",
    "    print(x) # 列表\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 120\n",
    "dataset = DataLoader(data\n",
    "           ,batch_size = bs\n",
    "           ,shuffle = True # 划分小批量之前请随机打乱数据\n",
    "           ,drop_last = False # 是否舍弃最后一个batch(500个样本分120，最后一个只有20)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7febe15501c0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-1.3346e+00, -9.5659e-01, -4.8822e-01,  3.3623e+00, -9.4634e-01],\n",
      "          [ 5.5837e-01,  9.0281e-01,  1.1138e+00, -6.3412e-01,  6.5767e-01],\n",
      "          [-4.6821e-01,  9.1996e-01,  1.7677e-01, -2.1329e+00, -1.0322e+00],\n",
      "          [-1.0133e+00,  3.7822e-01,  6.0810e-01, -1.7115e-02, -2.6411e-03]],\n",
      "\n",
      "         [[-1.1860e+00,  1.2023e-01, -2.3184e+00, -3.5003e-01, -8.0200e-01],\n",
      "          [ 4.0105e-01, -1.4007e+00, -1.5301e+00,  8.1988e-01, -1.3349e-02],\n",
      "          [ 7.3771e-01,  1.0310e-01,  6.1815e-01,  9.1976e-01, -1.1814e+00],\n",
      "          [ 8.6148e-01, -1.8494e+00,  1.3333e+00,  5.3396e-01,  1.1866e+00]],\n",
      "\n",
      "         [[ 2.4922e+00,  7.6012e-01, -9.8579e-01, -3.1428e-01,  2.4000e-02],\n",
      "          [-4.0303e-01,  4.9993e-01,  1.7167e+00,  5.3382e-01,  2.5988e-02],\n",
      "          [ 2.6928e-01, -4.9147e-01, -1.0665e+00,  1.5698e+00, -3.1296e+00],\n",
      "          [ 5.1460e-01, -1.2841e+00,  3.8885e-01, -2.5729e-01,  9.3518e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5414e+00,  2.4092e-01, -1.5182e-01,  5.2668e-01,  2.5021e-01],\n",
      "          [ 2.0543e+00, -7.1445e-01, -7.9340e-01,  4.2446e-01, -1.6978e+00],\n",
      "          [-4.0740e-01, -3.7689e-01,  3.4843e-01, -5.3975e-01, -1.6411e+00],\n",
      "          [-8.4780e-01,  3.9003e-01,  4.1812e-01, -3.2761e-01, -1.1881e+00]],\n",
      "\n",
      "         [[-1.0112e+00,  1.8345e+00, -4.8257e-01,  2.7245e-01, -8.2534e-01],\n",
      "          [-2.6354e-01, -2.2454e-02, -6.0556e-01, -4.3885e-01, -5.4582e-01],\n",
      "          [ 3.6624e-01,  2.3128e-01,  6.4718e-01, -7.0363e-01,  1.2828e+00],\n",
      "          [-5.5805e-01, -1.0171e+00, -1.7575e+00,  2.5900e-01,  1.1374e+00]],\n",
      "\n",
      "         [[ 4.6475e-01,  5.1400e-01,  2.1909e+00, -3.6818e-01, -7.2659e-01],\n",
      "          [ 1.6936e+00, -1.2658e+00, -1.2346e+00,  1.0657e+00, -1.2415e+00],\n",
      "          [-9.0464e-02,  5.3386e-01,  1.0193e+00, -6.7322e-01, -6.0969e-01],\n",
      "          [ 1.3005e+00,  6.0744e-01, -2.6714e-01, -7.0879e-01,  1.8055e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9704e-01,  1.1839e+00,  2.0540e-01, -5.2454e-01,  1.1696e+00],\n",
      "          [-1.2596e+00, -7.9688e-01, -7.7533e-01, -8.3496e-01, -3.9264e-01],\n",
      "          [-1.4393e+00,  2.9593e-01,  6.5109e-01,  8.7183e-01, -6.7731e-01],\n",
      "          [ 1.6056e+00,  5.5576e-01, -7.1684e-01, -2.8607e-01, -1.4939e+00]],\n",
      "\n",
      "         [[-8.0187e-01,  1.1756e+00, -5.8166e-01, -1.4951e+00,  3.9436e-01],\n",
      "          [ 1.7468e-01, -1.0403e+00,  2.3431e-01,  1.4421e+00, -8.8782e-01],\n",
      "          [-6.6513e-01, -8.2855e-01, -2.7930e-01, -4.1516e-01,  4.7172e-01],\n",
      "          [-3.4284e-01,  1.8509e+00, -9.6684e-01,  7.5337e-01,  4.6862e-01]],\n",
      "\n",
      "         [[ 1.5395e-01,  5.1173e-01,  1.5925e-01, -2.8430e+00,  4.7527e-01],\n",
      "          [ 7.6871e-01,  3.1328e-01, -1.0515e+00,  1.1984e+00,  5.7490e-01],\n",
      "          [-7.7065e-01, -2.8663e-02, -4.2865e-01, -2.6222e-01,  1.3214e-01],\n",
      "          [ 5.8493e-01, -6.4899e-01, -5.1475e-01,  2.8911e-01,  8.2943e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6040e+00, -2.0148e-01,  1.7529e+00,  5.6184e-01,  2.4588e-01],\n",
      "          [ 3.5761e-01,  9.3025e-01,  1.0338e+00, -9.4858e-01, -1.5338e+00],\n",
      "          [-9.8311e-01, -8.5227e-01,  1.6495e+00,  1.4962e+00, -7.9597e-01],\n",
      "          [ 8.9121e-01, -5.2549e-01, -2.3765e+00, -8.7398e-01,  1.4703e-02]],\n",
      "\n",
      "         [[-2.6398e+00, -7.7210e-01,  7.7526e-01,  5.3073e-01, -9.6388e-01],\n",
      "          [ 5.3262e-01, -3.5647e-01,  1.2952e+00,  9.3751e-01, -1.4707e+00],\n",
      "          [ 1.0806e+00, -2.5115e-01, -8.2057e-01,  1.0294e+00,  1.7600e+00],\n",
      "          [ 1.5397e+00,  7.8150e-01,  4.7755e-01, -1.6530e+00, -1.1915e+00]],\n",
      "\n",
      "         [[ 3.7309e-01, -1.3720e+00,  1.2683e-01, -9.6111e-01,  1.8556e-01],\n",
      "          [-1.0187e+00,  3.5672e-01, -7.5869e-01, -1.0537e+00,  2.6389e-01],\n",
      "          [ 2.8912e-01, -6.5441e-02, -4.4834e-01, -1.4229e+00, -1.4953e+00],\n",
      "          [-7.7601e-03,  7.4055e-02, -4.0694e-01, -3.2003e-01,  7.3760e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.7420e-01, -6.6726e-01,  1.3550e+00,  1.1281e+00,  1.0293e+00],\n",
      "          [ 1.3048e+00, -1.0943e+00, -9.7107e-02, -1.5250e-01, -1.6792e+00],\n",
      "          [-2.7363e+00,  1.6755e+00, -5.9039e-01, -7.9911e-01, -1.1976e+00],\n",
      "          [-2.2628e+00,  3.9489e-02,  1.0200e+00,  7.4179e-01, -5.3763e-01]],\n",
      "\n",
      "         [[-1.6200e-01, -8.5412e-01,  1.0219e+00, -1.0649e+00, -3.7039e-01],\n",
      "          [ 3.0414e-01,  5.6027e-01, -7.3803e-01, -1.1746e-01,  1.0245e+00],\n",
      "          [ 2.9139e+00, -1.1679e+00, -1.6662e+00,  3.7213e-01,  3.1872e-01],\n",
      "          [-4.7050e-01,  1.0158e+00, -1.3726e+00, -9.0015e-01,  1.3447e+00]],\n",
      "\n",
      "         [[-6.7523e-01, -9.5371e-02,  1.3079e+00, -1.9999e+00, -1.4002e-01],\n",
      "          [-4.6454e-01,  1.9891e-01, -3.7624e-01,  1.3708e-01,  6.4378e-01],\n",
      "          [-6.2372e-01, -4.2995e-01,  5.4933e-01, -9.5954e-01, -1.8736e+00],\n",
      "          [ 1.2593e+00,  1.5464e+00, -3.3143e-02, -4.3337e-01,  2.0877e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0316e-01,  6.9842e-01, -1.8957e+00, -1.2751e+00,  1.7778e+00],\n",
      "          [ 1.7754e+00,  4.2553e-01,  1.4855e+00, -5.4588e-01, -1.4702e+00],\n",
      "          [ 8.0884e-01, -5.5370e-01,  3.8135e-01, -8.4885e-01,  7.3735e-01],\n",
      "          [ 9.6206e-01, -2.0915e-01, -3.4599e-01,  2.0243e+00, -1.3157e+00]],\n",
      "\n",
      "         [[-5.7608e-02, -6.4651e-01, -2.0586e-01,  4.7344e-01,  5.1103e-01],\n",
      "          [ 1.2443e+00,  1.4349e+00, -1.1598e-01, -5.6313e-01, -1.4458e-01],\n",
      "          [-4.2609e-02,  5.1349e-01,  6.4445e-01,  1.9168e+00, -4.4846e-02],\n",
      "          [ 9.5364e-01,  8.4559e-01, -2.8242e-01, -1.0311e+00, -8.8158e-02]],\n",
      "\n",
      "         [[ 5.6128e-01, -7.9805e-01, -1.7996e-01, -9.3301e-01,  8.3899e-02],\n",
      "          [ 2.4689e-01,  1.7030e+00, -6.1391e-01, -2.7376e-01, -1.2367e+00],\n",
      "          [ 1.8892e+00,  8.8733e-01,  1.9719e-01, -1.3365e-01, -1.0970e+00],\n",
      "          [-4.4567e-01, -2.8037e-01,  1.7314e-01, -6.4938e-02, -1.9449e-01]]]]), tensor([[-0.9359],\n",
      "        [-0.4704],\n",
      "        [-2.0547],\n",
      "        [ 0.8200],\n",
      "        [ 1.2685],\n",
      "        [ 1.9411],\n",
      "        [ 1.2312],\n",
      "        [-0.0089],\n",
      "        [ 0.1902],\n",
      "        [-0.1643],\n",
      "        [ 1.0108],\n",
      "        [-0.2543],\n",
      "        [ 0.5740],\n",
      "        [-0.2541],\n",
      "        [-1.3843],\n",
      "        [-0.2677],\n",
      "        [-1.7942],\n",
      "        [ 0.6863],\n",
      "        [-2.1487],\n",
      "        [ 1.1726],\n",
      "        [-1.0089],\n",
      "        [ 0.9260],\n",
      "        [-0.3262],\n",
      "        [ 0.1280],\n",
      "        [ 0.4752],\n",
      "        [ 0.4812],\n",
      "        [ 0.0331],\n",
      "        [ 0.4294],\n",
      "        [-0.7052],\n",
      "        [-0.6302],\n",
      "        [ 1.3272],\n",
      "        [-0.1579],\n",
      "        [-0.0321],\n",
      "        [ 0.9310],\n",
      "        [ 1.9649],\n",
      "        [ 0.9974],\n",
      "        [-1.0609],\n",
      "        [-0.4932],\n",
      "        [ 0.9580],\n",
      "        [-0.4649],\n",
      "        [ 0.8075],\n",
      "        [-0.8157],\n",
      "        [ 1.3406],\n",
      "        [-0.9423],\n",
      "        [ 1.8167],\n",
      "        [-0.7108],\n",
      "        [-0.0621],\n",
      "        [-0.3572],\n",
      "        [ 1.8284],\n",
      "        [-0.8394],\n",
      "        [-0.5899],\n",
      "        [ 0.6450],\n",
      "        [-0.0921],\n",
      "        [ 1.0945],\n",
      "        [-0.6420],\n",
      "        [-0.9042],\n",
      "        [ 0.8340],\n",
      "        [-1.5114],\n",
      "        [ 0.2935],\n",
      "        [ 1.1397],\n",
      "        [-0.3463],\n",
      "        [ 0.3926],\n",
      "        [ 0.6943],\n",
      "        [-0.7698],\n",
      "        [-0.1803],\n",
      "        [-0.7023],\n",
      "        [-1.1071],\n",
      "        [ 0.3378],\n",
      "        [ 0.7752],\n",
      "        [-1.5339],\n",
      "        [ 0.5186],\n",
      "        [ 1.9287],\n",
      "        [-0.1876],\n",
      "        [-1.1283],\n",
      "        [-0.4089],\n",
      "        [-0.3663],\n",
      "        [-0.4762],\n",
      "        [-1.0657],\n",
      "        [ 0.4819],\n",
      "        [-1.2076],\n",
      "        [ 0.5910],\n",
      "        [ 2.3710],\n",
      "        [-0.0347],\n",
      "        [-0.6052],\n",
      "        [-0.4114],\n",
      "        [ 0.5963],\n",
      "        [-1.7836],\n",
      "        [-2.3581],\n",
      "        [ 0.4489],\n",
      "        [-0.2275],\n",
      "        [-1.4202],\n",
      "        [-1.0176],\n",
      "        [ 1.0284],\n",
      "        [-0.4305],\n",
      "        [-1.5767],\n",
      "        [ 0.1661],\n",
      "        [-0.6501],\n",
      "        [-0.5179],\n",
      "        [-0.2119],\n",
      "        [ 0.2326],\n",
      "        [ 0.8029],\n",
      "        [-0.1138],\n",
      "        [-1.3542],\n",
      "        [ 0.5131],\n",
      "        [ 0.0230],\n",
      "        [-0.1160],\n",
      "        [-0.4741],\n",
      "        [-1.0638],\n",
      "        [ 0.6639],\n",
      "        [ 1.7584],\n",
      "        [-1.3274],\n",
      "        [ 0.9523],\n",
      "        [-0.1885],\n",
      "        [-0.6386],\n",
      "        [ 1.7820],\n",
      "        [ 0.3640],\n",
      "        [-2.1222],\n",
      "        [ 0.4781],\n",
      "        [-0.3360],\n",
      "        [ 0.9140]])]\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i) # [ tensor([batch个特征]),tensor([batch个标签]) ]\n",
    "    print(i[0].shape) # batch个特征\n",
    "    print(i[1].shape) # batch个标签\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) # 一共有多少个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7febe1550610>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset #展示里面全部的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.dataset) # 全部样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.4229,  0.3269, -0.7064,  0.4886, -0.4457],\n",
       "          [-0.1819,  1.3381, -0.0515,  0.9612,  0.6173],\n",
       "          [ 2.1468,  0.0329, -1.3354, -0.2216, -1.2585],\n",
       "          [-0.0606, -0.7752,  1.5580,  0.8701,  2.0751]],\n",
       " \n",
       "         [[-0.4195,  0.3641,  1.1461,  1.3315,  0.6182],\n",
       "          [ 0.4945,  0.4110,  0.4114, -1.9308, -0.2237],\n",
       "          [ 0.4374,  0.4338,  0.5920,  0.7556, -0.4258],\n",
       "          [ 1.5789, -0.1794, -0.5889,  1.8905, -0.7718]],\n",
       " \n",
       "         [[-0.7557, -1.2767,  1.0856,  0.7704,  2.3633],\n",
       "          [ 0.0490, -0.9121, -0.0489, -1.2371, -1.2507],\n",
       "          [-2.2677, -0.1536, -0.2799, -0.9272,  1.4546],\n",
       "          [-0.8360, -0.3864, -0.9757, -0.5694,  0.2240]]]),\n",
       " tensor([-0.1178]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0] # 单个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1178])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][1] # 单个样本标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.batch_size # 查看现有的batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
