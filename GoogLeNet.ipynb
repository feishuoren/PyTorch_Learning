{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前沿网络SOTA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet（Inception V1）\n",
    "\n",
    "VGG 参数量过多，各层之间的链接过于稠密（Dense），计算量过大，容易过拟合。\n",
    "\n",
    "解决这个问题的方法：\n",
    "1. 消减参数量的操作，让网络整体变得“稀疏”\n",
    "2. 引入随机的稀疏性。如类似 Dropout 的方式来随机的让特征矩阵或权重矩阵中的部分数据为0\n",
    "3. 引入GPU进行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前解决方式的缺点：\n",
    "1. 在神经网络由稠密变得稀疏（Sparse）的过程中，网络的学习能力会波动甚至下降（稠密的学习能力强）\n",
    "2. 随机的稀疏性与GPU计算之间存在巨大矛盾。现代硬件不擅长处理在随机或非均匀稀疏的数据上的计算，并且不擅长在矩阵计算上表现得尤其明显"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - VGG：在学习能力更强的稠密架构上增加Dropout\n",
    " - GoogLeNet:使用普通卷积、池化层这些稠密元素组成的块去无限逼近（approximate）一个稀疏架构，从而构造一种参数量与稀疏网络相似的稠密网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet 团队使用了一个复杂的网络架构构造算法\n",
    "-> 并让算法向着 “使用稠密成分逼近稀疏架构” 的方向进行训练\n",
    "-> 产出多个可能有效的密集架构\n",
    "-> 进行大量的实验后，选出了学习能力最强的密集架构及其相关参数（这个架构就是Inception块，将其以某种方式串联起来就是GoogLeNet）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception块：\n",
    "对同一个输入并联四组卷积运算，得到不同通道数相同特征图尺寸的结果，进行拼接\n",
    "1. 1 * 1 卷积核：最大程度保留像素之间的位置信息\n",
    "2. 3 * 3 / 5 * 5 卷积核： 提取相邻像素之间的信息\n",
    "3. 最大池化：提取局部最有价值的信息\n",
    "\n",
    "- Inception块没有Dropout等，结构稠密\n",
    "- 在 3 * 3 / 5 * 5 卷积核之前的 `1 * 1` 有“聚类”(聚合信息)的作用，使得架构更加稠密，且加深网络深度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`辅助分类器`：除了主题架构中的softmax分类器之外，另外存在的两个分类器（softmax）。\n",
    "结构：\n",
    "- 平均池化层\n",
    "- 卷积层+ReLU\n",
    "- 全连接层+ReLU\n",
    "- Dropout（70%）\n",
    "- 全连接层+softmax\n",
    "\n",
    "在整体架构中，这两个分类器的输入分别是 inception4a 和 inception4d 的输出结果。也就是在这两层的后面，加上辅助分类器后，输出softmax结果。最后将这两个和全局架构中的softmax,这三个分类结果算三个损失函数值，对这三个损失函数值加权平均得到最终损失，基于这个损失反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "版本1有 LRN层（局部响应归一化），后来用 BN 层代替"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet 复现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv + BN + ReLU --basicconv\n",
    "# Inception\n",
    "# AUXclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,**kwargs): # 不写in_channels也可以\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels,out_channels,bias=False,**kwargs)\n",
    "                                 ,nn.BatchNorm2d(out_channels)\n",
    "                                 ,nn.ReLU(inplace=True))\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicConv2d(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试，目标：没有明显报错\n",
    "BasicConv2d(2,10,kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self\n",
    "                 ,in_channels : int\n",
    "                 ,ch1x1 : int\n",
    "                 ,ch3x3red : int\n",
    "                 ,ch3x3 : int\n",
    "                 ,ch5x5red : int\n",
    "                 ,ch5x5 : int\n",
    "                 ,pool_proj : int\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.branch1 = BasicConv2d(in_channels,ch1x1,kernel_size=1)\n",
    "        self.branch2 = nn.Sequential(BasicConv2d(in_channels,ch3x3red,kernel_size=1)\n",
    "                                    ,BasicConv2d(ch3x3red,ch3x3,kernel_size=3,padding=1))\n",
    "        self.branch3 = nn.Sequential(BasicConv2d(in_channels,ch5x5red,kernel_size=1)\n",
    "                                    ,BasicConv2d(ch5x5red,ch5x5,kernel_size=5,padding=2))\n",
    "        self.branch4 = nn.Sequential(nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "                                    ,BasicConv2d(in_channels,pool_proj,kernel_size=1))   \n",
    "        \n",
    "    def forward(self,x):\n",
    "        branch1 = self.branch1(x) # 28*28,chi1x1\n",
    "        branch2 = self.branch2(x) # 28*28,chi3x3\n",
    "        branch3 = self.branch3(x) # 28*28,chi5x5\n",
    "        branch4 = self.branch4(x) # 28*28,pool_proj\n",
    "        output = [branch1,branch2,branch3,branch4]\n",
    "        return torch.cat(output,1) # 合并 dim=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception(\n",
       "  (branch1): BasicConv2d(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (branch2): Sequential(\n",
       "    (0): BasicConv2d(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicConv2d(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (branch3): Sequential(\n",
       "    (0): BasicConv2d(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicConv2d(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (branch4): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (1): BasicConv2d(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "\"\"\"\n",
    " ,in_channels : int\n",
    " ,ch1x1 : int\n",
    " ,ch3x3red : int\n",
    " ,ch3x3 : int\n",
    " ,ch5x5red : int\n",
    " ,ch5x5 : int\n",
    " ,pool_proj : int\n",
    "\"\"\"\n",
    "Inception(192,64,96,128,16,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(10,192,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in3a = Inception(192,64,96,128,16,32,32)\n",
    "in3a(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辅助分类器的实现\n",
    "# auxiliary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxClf(nn.Module):\n",
    "    def __init__(self,in_channels:int,num_classes:int,**kwargs):\n",
    "        super().__init__()\n",
    "        self.feature_ = nn.Sequential(nn.AvgPool2d(kernel_size=5,stride=3)\n",
    "                                     ,BasicConv2d(in_channels,128,kernel_size=1))\n",
    "        self.clf_ = nn.Sequential(nn.Linear(4*4*128,1024)\n",
    "                                 ,nn.ReLU(inplace=True)\n",
    "                                 ,nn.Dropout(0.7)\n",
    "                                 ,nn.Linear(1024,num_classes))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.feature_(x)\n",
    "        x = x.view(-1,4*4*128)\n",
    "        x = self.clf_(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuxClf(\n",
       "  (feature_): Sequential(\n",
       "    (0): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
       "    (1): BasicConv2d(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (clf_): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.7, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4a后的辅助分类器\n",
    "AuxClf(512,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self,num_classes: int=1000, blocks = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if blocks is None:\n",
    "            blocks = [BasicConv2d,Inception,AuxClf]\n",
    "        conv_block = blocks[0]\n",
    "        inception_block = blocks[1]\n",
    "        aux_clf_block = blocks[2]\n",
    "        \n",
    "        # block1\n",
    "        self.conv1 = conv_block(3,64,kernel_size=7,stride=2,padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,ceil_mode=True)\n",
    "        \n",
    "        # block2\n",
    "        self.conv2 = conv_block(64,64,kernel_size=1)\n",
    "        self.conv3 = conv_block(64,192,kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3,stride=2,ceil_mode=True) # ceil_mode=True向上取整\n",
    "        \n",
    "        # block3\n",
    "        self.inception3a = inception_block(192,64,96,128,16,32,32)\n",
    "        self.inception3b = inception_block(256,128,128,192,32,96,64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3,stride=2,ceil_mode=True)\n",
    "        \n",
    "        # block4\n",
    "        self.inception4a = inception_block(480,192,96,208,16,48,64)\n",
    "        self.inception4b = inception_block(512,160,112,224,24,64,64)\n",
    "        self.inception4c = inception_block(512,128,128,256,24,64,64)\n",
    "        self.inception4d = inception_block(512,112,144,288,32,64,64)\n",
    "        self.inception4e = inception_block(528,256,160,320,32,128,128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3,stride=2,ceil_mode=True)\n",
    "        \n",
    "        # block5\n",
    "        self.inception5a = inception_block(832,256,160,320,32,128,128)\n",
    "        self.inception5b = inception_block(832,384,192,384,48,128,128)\n",
    "        \n",
    "        # clf\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1)) # 自适应池化参数：需要输出的特征图尺寸\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(1024,num_classes)\n",
    "        \n",
    "        # auxclf\n",
    "        self.aux1 = aux_clf_block(512, num_classes) # 4a\n",
    "        self.aux2 = aux_clf_block(528, num_classes) # 4d\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # block1\n",
    "        x = self.maxpool1(self.conv1(x))\n",
    "        \n",
    "        # block2\n",
    "        x = self.maxpool2(self.conv3(self.conv2(x)))\n",
    "        \n",
    "        # block3\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        # block3\n",
    "        x = self.inception4a(x)\n",
    "        aux1 = self.aux1(x)\n",
    "        \n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        aux2 = self.aux2(x)\n",
    "        \n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        # block5\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        \n",
    "        # clf\n",
    "        x = self.avgpool(x) # 在全局平均池化后，特征图尺寸变为1x1\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x, aux2, aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "data = torch.ones(10,3,224,224)\n",
    "\n",
    "net = GoogLeNet(num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2,fc1,fc0 = net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1000])\n",
      "torch.Size([10, 1000])\n",
      "torch.Size([10, 1000])\n"
     ]
    }
   ],
   "source": [
    "for i in [fc2,fc1,fc0]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "GoogLeNet                                     --                        --\n",
       "├─BasicConv2d: 1-1                            [10, 64, 112, 112]        9,536\n",
       "├─MaxPool2d: 1-2                              [10, 64, 56, 56]          --\n",
       "├─BasicConv2d: 1-3                            [10, 64, 56, 56]          4,224\n",
       "├─BasicConv2d: 1-4                            [10, 192, 56, 56]         110,976\n",
       "├─MaxPool2d: 1-5                              [10, 192, 28, 28]         --\n",
       "├─Inception: 1-6                              [10, 256, 28, 28]         164,064\n",
       "├─Inception: 1-7                              [10, 480, 28, 28]         389,376\n",
       "├─MaxPool2d: 1-8                              [10, 480, 14, 14]         --\n",
       "├─Inception: 1-9                              [10, 512, 14, 14]         376,800\n",
       "├─AuxClf: 1-10                                [10, 1000]                3,188,968\n",
       "├─Inception: 1-11                             [10, 512, 14, 14]         449,808\n",
       "├─Inception: 1-12                             [10, 512, 14, 14]         510,768\n",
       "├─Inception: 1-13                             [10, 528, 14, 14]         606,080\n",
       "├─AuxClf: 1-14                                [10, 1000]                3,191,016\n",
       "├─Inception: 1-15                             [10, 832, 14, 14]         869,376\n",
       "├─MaxPool2d: 1-16                             [10, 832, 7, 7]           --\n",
       "├─Inception: 1-17                             [10, 832, 7, 7]           1,044,480\n",
       "├─Inception: 1-18                             [10, 1024, 7, 7]          1,445,344\n",
       "├─AdaptiveAvgPool2d: 1-19                     [10, 1024, 1, 1]          --\n",
       "├─Dropout: 1-20                               [10, 1024]                --\n",
       "├─Linear: 1-21                                [10, 1000]                1,025,000\n",
       "===============================================================================================\n",
       "Total params: 13,385,816\n",
       "Trainable params: 13,385,816\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.91\n",
       "===============================================================================================\n",
       "Input size (MB): 6.02\n",
       "Forward/backward pass size (MB): 517.24\n",
       "Params size (MB): 53.54\n",
       "Estimated Total Size (MB): 576.81\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net,(10,3,224,224),device=\"cpu\",depth=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
